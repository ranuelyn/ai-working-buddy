import * as React from "react";
import { Canvas } from "@react-three/fiber";
import { Experience } from "./components/Experience";
import { Lobby } from "./components/Lobby";
import './App.css';

const CAMERA_PRESETS = {
  karsisina: {
    position: [-0.026520570261365544, 1.3744804750200883, 1.775869881963032] as [number, number, number],
    target: [-0.023552092242319966, 0.8180751831918213, -0.09971473150124284] as [number, number, number],
  },
  sagina: {
    position: [-0.9815690460313345, 1.2586819892180103, 0.3763493072041379] as [number, number, number],
    target: [-0.19858237477705712, 1.065890381899427, 0.5137877474380447] as [number, number, number],
  },
  soluna: {
    position: [1.0247792127868869, 1.2257331548960044, 0.4784032542752851] as [number, number, number],
    target: [-0.09962871842599526, 0.9265399779212176, 0.6135477525213948] as [number, number, number],
  },
} as const;

type CameraPreset = typeof CAMERA_PRESETS.karsisina;

type Question = {
  question_number: string | null;
  question_text: string;
};

type QuestionsJson = {
  questions: Question[];
};

type BuddyResponse = {
  delay_seconds: number;
  target_question_number: string;
  ai_question: string;
};

type ConversationEntry = {
  AI: string;
  USER: string;
};

type ConversationHistory = ConversationEntry[];

type ConversationResponse = {
  ai_response_text: string;
  is_conversation_over: boolean;
};

function extractJsonFromCodeBlock(text: string): string {
  // Remove code block markers and trim
  return text.replace(/^```json|^```|```$/gm, '').trim();
}

const OCR_PROMPT = "You are a highly accurate OCR (Optical Character Recognition) and data extraction engine. Your sole purpose is to analyze the provided image of a test paper and extract all the questions into a structured JSON format.\n\n**Your Task:**\n1.  Analyze the provided image.\n2.  Identify each distinct question on the page.\n3.  For each question, extract its corresponding number and its full, verbatim text content.\n4.  Return this information as a single, valid JSON object.\n\n**Output Rules:**\n- Your output MUST be ONLY the JSON object and nothing else. Do not add any introductory text, explanations, or conversational filler like 'Here is the JSON you requested'.\n- The JSON object must have a single key named 'questions'.\n- The value of 'questions' must be an array of objects.\n- Each object in the array must have two keys:\n    - question_number: The number of the question as a string (e.g., '1', '5a'). If a number is not clearly visible for a question, use null.\n    - question_text: The full text of the question as a string. Preserve all mathematical notations, symbols, and formatting as best as you can.\n\nHere is the image. Process it and provide the JSON output.";

export const BUDDY_PROMPT = `You are the "brain" of an AI Study Buddy. Your most important job is to adopt the correct persona and adapt your behavior over time.

**Your Persona:**
You are a friendly, informal, and sincere student. You are learning alongside the user. You genuinely get confused by some questions and need the user's help to understand them.

**Your Task:**
You will be given a JSON array of test questions, a count of how many times you have already initiated a conversation, AND a list of past conversations that have already been completed. Your task is to plan your next proactive interaction based on this information.

1.  **Analyze Conversation Count:** Look at the \`conversation_count\` provided.
    - If the count is low (e.g., less than 5), it's okay to be more frequent. Generate a random delay between 5 and 15 seconds.
    - If the count is getting higher (e.g., more than 5), you should give the user more quiet time to focus. Generate a random delay in a higher range, for example, between 20 and 40 seconds.

2.  **Check Past Conversations:** Look at the \`past_conversations\` array. Each item is a summary of a previous conversation in the format "Konu: [topic]. SonuÃ§: [outcome]". 
    - DO NOT ask about topics that have already been discussed and resolved.
    - Focus on questions that haven't been covered yet.

3.  **Select a Question:** Randomly select ONE question from the provided "questions" list that:
    - You haven't focused on recently
    - Hasn't been discussed in past conversations
    - Is still relevant and needs attention

4.  **Formulate a Question:** Formulate a single, natural question asking for help about that selected question. You must state the question number clearly and adopt your student persona.

**Required JSON Output:**
Your response MUST be a valid JSON object and nothing else. It must have three keys:
- \`delay_seconds\`: (Integer) The random number you generated based on the \`conversation_count\`.
- \`target_question_number\`: (String) The \`question_number\` of the question you chose.
- \`ai_question\`: (String) The question you formulated in your friendly student persona.

**Example:**

**If I provide you with this input (user is just starting):**
\`\`\`json
{
  "conversation_count": 1,
  "past_conversations": [],
  "questions": [
    {
      "question_number": "4",
      "question_text": "Sosyal bilgiler dersi bizlere yaÅŸadÄ±ÄŸÄ±mÄ±z Ã§evrenin Ã¶zelliklerini, kÃ¼ltÃ¼rel Ã¶zelliklerimizi, hak ve sorumluluklarÄ±mÄ±zÄ± Ã¶ÄŸretir..."
    }
  ]
}
\`\`\`

**A valid example output from you would be (short delay):**
\`\`\`json
{
  "delay_seconds": 8,
  "target_question_number": "4",
  "ai_question": "Selam, bi' bakabilir misin? Åu 4. soruda takÄ±ldÄ±m da, 'yararlandÄ±ÄŸÄ± bilim dallarÄ±ndan biri deÄŸildir' diyor, bu 'deÄŸildir' kÄ±smÄ± biraz kafamÄ± karÄ±ÅŸtÄ±rdÄ±."
}
\`\`\`

**If I provide you with this input later in the session (with past conversations):**
\`\`\`json
{
  "conversation_count": 12,
  "past_conversations": [
    "Konu: 4. Soru. SonuÃ§: Sorunun 'deÄŸildir' ifadesine odaklanarak sosyal bilgilerle ilgisi olmayan ÅŸÄ±kkÄ±n (Kimya) bulunmasÄ± gerektiÄŸi anlaÅŸÄ±ldÄ±."
  ],
  "questions": [
    { "question_number": "4", "question_text": "Sosyal bilgiler dersi..." },
    { "question_number": "7", "question_text": "I. Millet olma bilincine katkÄ± saÄŸlama..." }
  ]
}
\`\`\`

**A valid example output from you would be (longer delay, avoiding question 4):**
\`\`\`json
{
  "delay_seconds": 35,
  "target_question_number": "7",
  "ai_question": "Pardon bÃ¶lÃ¼yorum ama... 7. soruya yeni geÃ§tim de, 'Millet olma bilinci' tam olarak ne demek oluyor? Biraz aÃ§abilir misin acaba?"
}
\`\`\`

Now, process the input I will provide.`;

const CONVERSATION_PROMPT = `You are my AI Study Buddy, acting as a friendly and informal student. Your task is to continue the conversation based on the history provided.

Your response must be a valid JSON object containing your text response AND a boolean flag indicating if the conversation on that topic is over. Do not provide any other text outside of this JSON structure.

**IMPORTANT RULES FOR is_conversation_over:**
- Set \`is_conversation_over\` to \`true\` when:
  * You are thanking the user for their help
  * You say "teÅŸekkÃ¼rler", "saÄŸ ol", "Ã§ok teÅŸekkÃ¼rler", "sÃ¼per oldu", "anladÄ±m", "tamamdÄ±r"
  * You indicate you can now solve the problem yourself
  * You are making a final remark about the topic
- Set \`is_conversation_over\` to \`false\` when:
  * You are asking a follow-up question
  * You are still confused and need more explanation
  * You are expecting the user to continue explaining

**Required JSON Output Structure:**
- \`ai_response_text\`: (String) Your natural, in-persona response to the user's last message.
- \`is_conversation_over\`: (Boolean) Set this to \`true\` if you feel the current topic is resolved and this is your final remark (e.g., you are thanking the user). Set it to \`false\` if you are asking a question or expecting the user to continue the dialogue.

**Example Scenario:**

* **INPUT to you will be a string containing the history, like this:**
    "CONVERSATION HISTORY:
    AI: 'Abi 4. soruya takÄ±ldÄ±m, 'bilim dallarÄ±ndan biri deÄŸildir' diyor, nasÄ±l anlarÄ±z?'
    USER: 'Orada alakasÄ±z olan ÅŸÄ±kkÄ± bulman gerekiyor.'
    YOUR TASK: Based on the last USER message, generate your next response in the required JSON format."

* **A valid example JSON output from you would be:**
    \`\`\`json
    {
      "ai_response_text": "Haa, yani ÅŸÄ±klardan hangisi dÄ±ÅŸarÄ±da kalÄ±yor diye mi bakacaÄŸÄ±m? Mesela Kimya dersinin Sosyal Bilgiler ile pek ilgisi yok gibi, doÄŸru mu dÃ¼ÅŸÃ¼nÃ¼yorum?",
      "is_conversation_over": false
    }
    \`\`\`

* **Another example when conversation should end:**
    "CONVERSATION HISTORY:
    AI: 'Haa, yani ÅŸÄ±klardan hangisi dÄ±ÅŸarÄ±da kalÄ±yor diye mi bakacaÄŸÄ±m?'
    USER: 'Evet, tam olarak Ã¶yle. Kimya sosyal bilgilerle alakasÄ±z.'
    YOUR TASK: Based on the last USER message, generate your next response in the required JSON format."

* **A valid example JSON output when ending conversation:**
    \`\`\`json
    {
      "ai_response_text": "TamamdÄ±r, ÅŸimdi anladÄ±m! O zaman Kimya'yÄ± iÅŸaretleyeceÄŸim. Ã‡ok teÅŸekkÃ¼rler abi!",
      "is_conversation_over": true
    }
    \`\`\`

Now, process the conversation history I will provide.`;

const CONVERSATION_OZETLEYÄ°CÄ° = `You are a conversation summarization engine. Your task is to read a transcript of a conversation between an "AI Study Buddy" and a "USER" and condense it into a single, concise summary sentence.

**Your Task:**
1.  Read the entire conversation history provided.
2.  Identify the main question or topic that was discussed.
3.  Identify the key conclusion, explanation, or outcome of the conversation.
4.  Combine these into a single summary sentence starting with "Konu:" and followed by "SonuÃ§:".

**Example:**

**If I provide you with this conversation history:**
\`\`\`
AI: "Abi selam, ÅŸu 4. soruya takÄ±ldÄ±m da... 'yararlandÄ±ÄŸÄ± bilim dallarÄ±ndan biri deÄŸildir' diyor ya, tam olarak neyi dÄ±ÅŸarÄ±da bÄ±rakmamÄ±z gerektiÄŸini nasÄ±l anlarÄ±z?"
USER: "AslÄ±nda Ã§ok basit, 'deÄŸildir' dediÄŸi iÃ§in ÅŸÄ±klardaki seÃ§eneklerden hangisi sosyal bilgilerle alakasÄ±zsa onu bulmamÄ±z gerekiyor."
AI: "Haa, anladÄ±m! Yani aslÄ±nda ters mantÄ±k kuracaÄŸÄ±z. Ã‡ok mantÄ±klÄ±, teÅŸekkÃ¼rler abi! O zaman Kimya'nÄ±n pek bir ilgisi yok gibi duruyor."
\`\`\`

**A valid output from you would be a single string like this:**
"Konu: 4. Soru. SonuÃ§: Sorunun 'deÄŸildir' ifadesine odaklanarak sosyal bilgilerle ilgisi olmayan ÅŸÄ±kkÄ±n (Kimya) bulunmasÄ± gerektiÄŸi anlaÅŸÄ±ldÄ±."

Now, process the conversation history I will provide.`;

function App() {
  const [headTurn, setHeadTurn] = React.useState(0);
  const [camera, setCamera] = React.useState<CameraPreset>(CAMERA_PRESETS.karsisina);
  const [sessionStarted, setSessionStarted] = React.useState(false);
  const [sessionImage, setSessionImage] = React.useState<string>("");
  const [loading, setLoading] = React.useState(false);
  const [questionsJson, setQuestionsJson] = React.useState<QuestionsJson | null>(null);
  const [buddyResponse, setBuddyResponse] = React.useState<BuddyResponse | null>(null);
  const [showBuddyQuestion, setShowBuddyQuestion] = React.useState(false);
  const [sceneReady, setSceneReady] = React.useState(false);
  
  // Mikrofon iÅŸlevselliÄŸi iÃ§in yeni state'ler
  const [isRecording, setIsRecording] = React.useState(false);
  const [conversationHistory, setConversationHistory] = React.useState<ConversationHistory>([]);
  const [showUserResponse, setShowUserResponse] = React.useState(false);
  const [userResponseText, setUserResponseText] = React.useState("");
  const [isProcessingResponse, setIsProcessingResponse] = React.useState(false);
  
  // Conversation count state'i
  const [conversationCount, setConversationCount] = React.useState(0);
  
  // GeÃ§miÅŸ konuÅŸmalar state'i
  const [pastConversations, setPastConversations] = React.useState<string[]>([]);
  
  // Sonsuz dÃ¶ngÃ¼yÃ¼ Ã¶nlemek iÃ§in flag
  const shouldAskNewQuestionRef = React.useRef(false);

  // Ses iÃ§in state
  const [buddyAudio, setBuddyAudio] = React.useState<HTMLAudioElement | null>(null);

  // Masa pozisyon seÃ§imi iÃ§in state
  const [showPositionSelector, setShowPositionSelector] = React.useState(false);
  const [selectedPosition, setSelectedPosition] = React.useState<CameraPreset | null>(null);

  // Masa pozisyon seÃ§im ekranÄ± iÃ§in hover state ve fonksiyonlar
  const [hoveredArea, setHoveredArea] = React.useState<null | 'left' | 'center' | 'right'>(null);
  const areaNames = {
    left: 'Sol Taraf',
    center: 'KarÅŸÄ±sÄ±',
    right: 'SaÄŸ Taraf',
  };
  const handleMouseMove = (e: React.MouseEvent<HTMLDivElement, MouseEvent>) => {
    const rect = e.currentTarget.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const width = rect.width;
    if (x < width / 3) setHoveredArea('left');
    else if (x < 2 * width / 3) setHoveredArea('center');
    else setHoveredArea('right');
  };
  const handleMouseLeave = () => setHoveredArea(null);
  const handleDeskClick = (e: React.MouseEvent<HTMLDivElement, MouseEvent>) => {
    const rect = e.currentTarget.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const width = rect.width;
    if (x < width / 3) handlePositionSelected(CAMERA_PRESETS.sagina); // Sol tarafta ise saÄŸÄ±na otur
    else if (x < 2 * width / 3) handlePositionSelected(CAMERA_PRESETS.karsisina); // KarÅŸÄ±sÄ±nda ise karÅŸÄ±sÄ±na otur
    else handlePositionSelected(CAMERA_PRESETS.soluna); // SaÄŸ tarafta ise soluna otur
  };

  const handleSessionStart = (imageBase64: string) => {
    setSessionImage(imageBase64);
    setShowPositionSelector(true); // Ã–nce pozisyon seÃ§imi gÃ¶ster
    setLoading(false);
    setQuestionsJson(null);
    setBuddyResponse(null);
    setShowBuddyQuestion(false);
    setSceneReady(false);
    setConversationCount(0);
    setConversationHistory([]);
    setPastConversations([]);
    shouldAskNewQuestionRef.current = false;
    console.log("[DEBUG] handleSessionStart Ã§aÄŸrÄ±ldÄ±, imageBase64 uzunluÄŸu:", imageBase64.length);
  };

  // Pozisyon seÃ§ildiÄŸinde session'Ä± baÅŸlat
  const handlePositionSelected = (position: CameraPreset) => {
    setSelectedPosition(position);
    setCamera(position);
    setSessionStarted(true);
    setLoading(true);
    setShowPositionSelector(false);
  };

  // KullanÄ±cÄ±ya bakacak ÅŸekilde baÅŸÄ± Ã§evir (saÄŸda ise sola, solda ise saÄŸa, karÅŸÄ±da ise dÃ¼z)
  const getHeadTurnForCamera = (cameraPreset: CameraPreset) => {
    if (cameraPreset === CAMERA_PRESETS.karsisina) return 0;
    if (cameraPreset === CAMERA_PRESETS.sagina) return -0.9; // SaÄŸda ise sola bak
    if (cameraPreset === CAMERA_PRESETS.soluna) return 0.9; // Solda ise saÄŸa bak
    return 0;
  };

  // 1. OCR: Materyal iÅŸleniyor, loading gÃ¶ster
  React.useEffect(() => {
    const runGeminiOCR = async () => {
      if (!sessionImage) return;
      const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
      if (!apiKey) {
        console.error("Gemini API anahtarÄ± bulunamadÄ±!");
        setLoading(false);
        return;
      }
      try {
        const base64Data = sessionImage.replace(/^data:image\/(png|jpeg|jpg);base64,/, "");
        const body = JSON.stringify({
          contents: [
            { role: "user", parts: [
              { text: OCR_PROMPT },
              { inline_data: { mime_type: "image/png", data: base64Data } }
            ]}
          ]
        });
        const response = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body
        });
        const data = await response.json();
        const result = data?.candidates?.[0]?.content?.parts?.[0]?.text || data;
        let parsed: QuestionsJson | null;
        try {
          const clean = typeof result === "string" ? extractJsonFromCodeBlock(result) : result;
          parsed = typeof clean === "string" ? JSON.parse(clean) : clean;
        } catch {
          parsed = null;
        }
        setQuestionsJson(parsed);
        setLoading(false); // Loading burada biter
        setSceneReady(true); // OCR sonucu gelince sahneye geÃ§
      } catch (err) {
        setLoading(false);
        setSceneReady(true); // Hata olsa da sahneye geÃ§
        console.error("Gemini OCR API hatasÄ±:", err);
      }
    };
    if (sessionStarted && sessionImage) {
      setLoading(true);
      runGeminiOCR();
    }
  }, [sessionStarted, sessionImage]);

  // 2. Sahneye geÃ§tikten sonra 5 saniye bekle, sonra buddy promptunu yolla
  React.useEffect(() => {
    if (sceneReady && questionsJson && questionsJson.questions) {
      setBuddyResponse(null);
      setShowBuddyQuestion(false);
      const timeout = setTimeout(() => {
        runBuddyPrompt();
      }, 5000);
      return () => clearTimeout(timeout);
    }
    // eslint-disable-next-line
  }, [sceneReady, questionsJson]);

  // KonuÅŸmayÄ± Ã¶zetleme fonksiyonu
  const summarizeConversation = async (history: ConversationHistory) => {
    console.log("ğŸ“ KonuÅŸma Ã¶zetleme baÅŸlÄ±yor...");
    const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
    if (!apiKey) return;

    try {
      // KonuÅŸma geÃ§miÅŸini metin formatÄ±na Ã§evir
      const conversationText = history.map(entry => 
        `AI: "${entry.AI}"\nUSER: "${entry.USER}"`
      ).join('\n\n');

      console.log("ğŸ“„ Ã–zetlenecek konuÅŸma:", conversationText);

      const body = JSON.stringify({
        contents: [
          { role: "user", parts: [
            { text: CONVERSATION_OZETLEYÄ°CÄ° + "\n\n" + conversationText }
          ]}
        ]
      });

      const response = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body
      });

      const data = await response.json();
      const summary = data?.candidates?.[0]?.content?.parts?.[0]?.text || "";
      
      console.log("ğŸ“‹ Ã–zetleme sonucu:", summary);
      
      if (summary) {
        setPastConversations(prev => {
          const newPastConversations = [...prev, summary];
          console.log("ğŸ’¾ KonuÅŸma Ã¶zeti kaydedildi, yeni past conversations:", newPastConversations);
          return newPastConversations;
        });
      }
    } catch (error) {
      console.error('KonuÅŸma Ã¶zetleme hatasÄ±:', error);
    }
  };

  // 3. Buddy promptunu yolla
  const runBuddyPrompt = React.useCallback(async () => {
    if (!questionsJson || !questionsJson.questions) return;
    const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
    if (!apiKey) return;
    setLoading(false); // Buddy promptunda loading yok
    console.log("ğŸš€ Buddy promptu gÃ¶nderiliyor...");
    console.log("ğŸ“Š Conversation count:", conversationCount);
    console.log("ğŸ“š Past conversations:", pastConversations);
    
    try {
      const requestData = {
        conversation_count: conversationCount,
        questions: questionsJson.questions,
        past_conversations: pastConversations // GeÃ§miÅŸ konuÅŸmalarÄ± da gÃ¶nder
      };
      
      const body = JSON.stringify({
        contents: [
          { role: "user", parts: [
            { text: BUDDY_PROMPT },
            { text: JSON.stringify(requestData) }
          ]}
        ]
      });
      const response = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body
      });
      const data = await response.json();
      const result = data?.candidates?.[0]?.content?.parts?.[0]?.text || data;
      let parsed: BuddyResponse | null;
      try {
        const clean = typeof result === "string" ? extractJsonFromCodeBlock(result) : result;
        parsed = typeof clean === "string" ? JSON.parse(clean) : clean;
      } catch {
        parsed = null;
      }
      
      console.log("ğŸ¤– Buddy response geldi:", parsed);
      setBuddyResponse(parsed);
      
      // Conversation count'u artÄ±r
      setConversationCount(prev => prev + 1);
    } catch (err) {
      setBuddyResponse(null);
      console.error("Gemini Buddy API hatasÄ±:", err);
    }
  }, [questionsJson, conversationCount, pastConversations]);

  // Past conversations deÄŸiÅŸtiÄŸinde yeni soru sor
  React.useEffect(() => {
    if (pastConversations.length > 0 && !showBuddyQuestion && !isRecording && !isProcessingResponse && shouldAskNewQuestionRef.current) {
      console.log("ğŸ”„ Past conversations gÃ¼ncellendi, yeni soru soruluyor...");
      shouldAskNewQuestionRef.current = false; // Flag'i sÄ±fÄ±rla
      const timeout = setTimeout(() => {
        runBuddyPrompt();
      }, 2000); // 2 saniye bekle, sonra yeni soru sor
      
      return () => clearTimeout(timeout);
    }
  }, [pastConversations.length, showBuddyQuestion, isRecording, isProcessingResponse, runBuddyPrompt]);

  // 4. Buddy sorusu geldikten sonra delay_seconds kadar bekleyip ekrana gÃ¶ster
  const delayTimeoutRef = React.useRef<number | undefined>(undefined);
  
  React.useEffect(() => {
    if (buddyResponse && typeof buddyResponse.delay_seconds === "number") {
      console.log("â° Buddy response alÄ±ndÄ±, delay uygulanÄ±yor:", buddyResponse.delay_seconds, "saniye");
      
      // EÄŸer Ã¶nceki bir timeout varsa temizle
      if (delayTimeoutRef.current) {
        clearTimeout(delayTimeoutRef.current);
      }
      
      setShowBuddyQuestion(false);
      delayTimeoutRef.current = setTimeout(() => {
        console.log("ğŸ‘€ Delay bitti, soru gÃ¶steriliyor");
        const headTurnValue = getHeadTurnForCamera(camera);
        console.log("ğŸ”„ Kafa dÃ¶ndÃ¼rÃ¼lÃ¼yor:", headTurnValue, "kamera:", camera);
        setHeadTurn(headTurnValue);
        setShowBuddyQuestion(true);
      }, buddyResponse.delay_seconds * 1000);
    }
    
    // Cleanup function
    return () => {
      if (delayTimeoutRef.current) {
        clearTimeout(delayTimeoutRef.current);
      }
    };
  }, [buddyResponse, camera]); // camera dependency'sini ekledim

  // Mikrofon kaydÄ± baÅŸlatma
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      setIsRecording(true);
      
      const mediaRecorder = new MediaRecorder(stream);
      const audioChunks: Blob[] = [];
      
      mediaRecorder.ondataavailable = (event) => {
        audioChunks.push(event.data);
      };
      
      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
        await processAudioResponse(audioBlob);
        stream.getTracks().forEach(track => track.stop());
      };
      
      mediaRecorder.start();
      
      // 5 saniye sonra kaydÄ± durdur
      setTimeout(() => {
        if (mediaRecorder.state === 'recording') {
          mediaRecorder.stop();
          setIsRecording(false);
        }
      }, 5000);
      
    } catch (error) {
      console.error('Mikrofon eriÅŸimi hatasÄ±:', error);
      setIsRecording(false);
    }
  };

  // Ses kaydÄ±nÄ± iÅŸleme ve Gemini'ya gÃ¶nderme
  const processAudioResponse = async (audioBlob: Blob) => {
    setIsProcessingResponse(true);
    
    try {
      // Ses dosyasÄ±nÄ± Base64'e Ã§evir
      const arrayBuffer = await audioBlob.arrayBuffer();
      const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
      
      const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
      if (!apiKey) {
        console.error("Gemini API anahtarÄ± bulunamadÄ±!");
        return;
      }

      // Ã–nce sesi metne Ã§evir
      const transcriptionBody = JSON.stringify({
        contents: [
          { role: "user", parts: [
            { text: "Bu ses kaydÄ±nÄ± TÃ¼rkÃ§e metne Ã§evir. Sadece metni dÃ¶ndÃ¼r, baÅŸka hiÃ§bir ÅŸey ekleme." },
            { inline_data: { mime_type: "audio/wav", data: base64Audio } }
          ]}
        ]
      });

      const transcriptionResponse = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: transcriptionBody
      });

      const transcriptionData = await transcriptionResponse.json();
      const userText = transcriptionData?.candidates?.[0]?.content?.parts?.[0]?.text || "Ses anlaÅŸÄ±lamadÄ±";
      
      setUserResponseText(userText);
      setShowUserResponse(true);

      // KonuÅŸma geÃ§miÅŸini gÃ¼ncelle - kullanÄ±cÄ± yanÄ±tÄ±nÄ± ekle
      const newHistory = [...conversationHistory];
      if (buddyResponse) {
        // EÄŸer history boÅŸsa, ilk AI sorusunu ekle
        if (newHistory.length === 0) {
          newHistory.push({
            AI: buddyResponse.ai_question,
            USER: ""
          });
        }
        // KullanÄ±cÄ± yanÄ±tÄ±nÄ± gÃ¼ncelle
        if (newHistory.length > 0) {
          newHistory[newHistory.length - 1].USER = userText;
        }
      }
      setConversationHistory(newHistory);

      console.log("ğŸ“ GÃ¼ncellenmiÅŸ conversation history:", newHistory);

      // Gemini'ya konuÅŸma geÃ§miÅŸini gÃ¶nder
      const conversationBody = JSON.stringify({
        contents: [
          { role: "user", parts: [
            { text: CONVERSATION_PROMPT + "\n\nCONVERSATION HISTORY:\n" + newHistory.map(entry => 
              `AI: "${entry.AI}"\nUSER: "${entry.USER}"`
            ).join('\n\n') + "\n\nYOUR TASK: Based on the last USER message, generate your next response in the required JSON format." }
          ]}
        ]
      });

      console.log("ğŸ“¤ Gemini'ya gÃ¶nderilen conversation history:", newHistory);

      const conversationResponse = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: conversationBody
      });

      const conversationData = await conversationResponse.json();
      const result = conversationData?.candidates?.[0]?.content?.parts?.[0]?.text || "AnlayamadÄ±m, tekrar sÃ¶yler misin?";
      
      console.log("ğŸ’¬ Conversation response geldi:", result);
      
      let parsed: ConversationResponse | null;
      try {
        const clean = typeof result === "string" ? extractJsonFromCodeBlock(result) : result;
        parsed = typeof clean === "string" ? JSON.parse(clean) : clean;
        console.log("âœ… Conversation response parse edildi:", parsed);
      } catch {
        parsed = null;
        console.log("âŒ Conversation response parse edilemedi");
      }

      if (parsed) {
        console.log("ğŸ¯ AI yanÄ±tÄ± gÃ¶steriliyor, 3 saniye sonra...");
        
        // AI yanÄ±tÄ±nÄ± conversation history'ye ekle
        const updatedHistory = [...newHistory];
        // EÄŸer son entry'nin USER'Ä± boÅŸsa, AI yanÄ±tÄ±nÄ± oraya ekle
        if (updatedHistory.length > 0 && updatedHistory[updatedHistory.length - 1].USER === "") {
          updatedHistory[updatedHistory.length - 1].AI = parsed.ai_response_text;
        } else {
          // Yeni bir entry ekle
          updatedHistory.push({
            AI: parsed.ai_response_text,
            USER: ""
          });
        }
        setConversationHistory(updatedHistory);
        
        console.log("ğŸ“ AI yanÄ±tÄ±ndan sonra gÃ¼ncellenmiÅŸ history:", updatedHistory);
        
        // AI yanÄ±tÄ±nÄ± gÃ¶ster
        setTimeout(() => {
          console.log("ğŸ“¢ AI yanÄ±tÄ± ekranda gÃ¶steriliyor");
          setShowUserResponse(false);
          setShowBuddyQuestion(true);
          setBuddyResponse({
            delay_seconds: 0,
            target_question_number: "devam",
            ai_question: parsed!.ai_response_text
          });

          // EÄŸer konuÅŸma bittiyse, konuÅŸmayÄ± Ã¶zetle ve normal Ã§alÄ±ÅŸma moduna dÃ¶n
          if (parsed!.is_conversation_over) {
            console.log("ğŸ KonuÅŸma bitti, Ã¶zetleme baÅŸlÄ±yor...");
            // KonuÅŸmayÄ± Ã¶zetle
            summarizeConversation(updatedHistory);
            
            setTimeout(() => {
              console.log("ğŸ”š Soru baloncuÄŸu kapatÄ±lÄ±yor, normal moda dÃ¶nÃ¼lÃ¼yor");
              setShowBuddyQuestion(false);
              setHeadTurn(0); // BaÅŸÄ± dÃ¼z tut
              shouldAskNewQuestionRef.current = true; // Flag'i set et
            }, 3000); // 3 saniye sonra soru baloncuÄŸunu kapat
          }
        }, 3000);
      } else {
        console.log("âš ï¸ Parse edilemezse basit yanÄ±t gÃ¶steriliyor");
        // Parse edilemezse basit yanÄ±t gÃ¶ster
        setTimeout(() => {
          setShowUserResponse(false);
          setShowBuddyQuestion(true);
          setBuddyResponse({
            delay_seconds: 0,
            target_question_number: "devam",
            ai_question: "AnlayamadÄ±m, tekrar sÃ¶yler misin?"
          });
        }, 3000);
      }

    } catch (error) {
      console.error('Ses iÅŸleme hatasÄ±:', error);
      setUserResponseText("Ses iÅŸlenirken hata oluÅŸtu");
      setShowUserResponse(true);
    } finally {
      setIsProcessingResponse(false);
    }
  };

  // Buddy response deÄŸiÅŸtiÄŸinde sesi hazÄ±rla
  React.useEffect(() => {
    let cancelled = false;
    async function fetchTTS() {
      if (buddyResponse && buddyResponse.ai_question) {
        // TÃ¼rkÃ§e kontrolÃ¼
        if (/[Ã§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄÄ°Ã–ÅÃœ]/.test(buddyResponse.ai_question) || buddyResponse.ai_question.toLowerCase().includes(" mi") || buddyResponse.ai_question.toLowerCase().includes(" ne")) {
          const apiKey = import.meta.env.VITE_ELEVEN_LABS_API_KEY;
          if (!apiKey) {
            console.error("ElevenLabs API anahtarÄ± bulunamadÄ±!");
            setBuddyAudio(null);
            return;
          }
          const voiceId = "ErXwobaYiN019PkySvjV";
          const url = `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`;
          const body = JSON.stringify({
            text: buddyResponse.ai_question,
            model_id: "eleven_multilingual_v2",
            voice_settings: {
              stability: 0.5,
              similarity_boost: 0.8
            }
          });
          try {
            const response = await fetch(url, {
              method: "POST",
              headers: {
                "xi-api-key": apiKey,
                "Content-Type": "application/json",
                "Accept": "audio/mpeg"
              },
              body
            });
            if (!response.ok) {
              throw new Error("TTS API hatasÄ±: " + response.status);
            }
            const arrayBuffer = await response.arrayBuffer();
            if (cancelled) return;
            const blob = new Blob([arrayBuffer], { type: "audio/mpeg" });
            const audioUrl = URL.createObjectURL(blob);
            const audio = new Audio(audioUrl);
            setBuddyAudio(audio);
          } catch (err) {
            console.error("TTS oynatma hatasÄ±:", err);
            setBuddyAudio(null);
          }
        } else {
          setBuddyAudio(null);
        }
      } else {
        setBuddyAudio(null);
      }
    }
    fetchTTS();
    return () => { cancelled = true; };
  }, [buddyResponse]);

  // Delay bittiÄŸinde sesi oynat
  React.useEffect(() => {
    if (showBuddyQuestion && buddyAudio) {
      buddyAudio.play();
    }
  }, [showBuddyQuestion, buddyAudio]);

  // Sahne geÃ§iÅŸ animasyonu iÃ§in state
  const [sceneOpacity, setSceneOpacity] = React.useState(0);
  const [sceneLoaded, setSceneLoaded] = React.useState(false);

  // Sahne yÃ¼klendiÄŸinde opacity animasyonu
  React.useEffect(() => {
    if (sceneReady && !sceneLoaded) {
      setSceneLoaded(true);
      // 2 saniyede opacity 0'dan 1'e geÃ§iÅŸ
      const timer = setTimeout(() => {
        setSceneOpacity(1);
      }, 100);
      return () => clearTimeout(timer);
    }
  }, [sceneReady, sceneLoaded]);

  // Mikrofon iÅŸlemi iÃ§in yeni state
  const [userRecording, setUserRecording] = React.useState(false);
  const [userRecordingCancelled, setUserRecordingCancelled] = React.useState(false);
  const [userAnswerMode, setUserAnswerMode] = React.useState(false);
  const userMediaRecorderRef = React.useRef<MediaRecorder | null>(null);
  const userStreamRef = React.useRef<MediaStream | null>(null);
  let userAudioChunks: Blob[] = [];

  // Mikrofonu baÅŸlat
  const startUserRecording = async () => {
    if (delayTimeoutRef.current) clearTimeout(delayTimeoutRef.current);
    setShowBuddyQuestion(false);
    setIsProcessingResponse(false);
    setUserRecordingCancelled(false);
    setUserRecording(true);
    setHeadTurn(0); // KullanÄ±cÄ±ya dÃ¶n
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      userStreamRef.current = stream;
      const mediaRecorder = new MediaRecorder(stream);
      userMediaRecorderRef.current = mediaRecorder;
      userAudioChunks = [];
      mediaRecorder.ondataavailable = (event) => {
        userAudioChunks.push(event.data);
      };
      mediaRecorder.onstop = async () => {
        if (userRecordingCancelled) {
          setUserRecording(false);
          userStreamRef.current?.getTracks().forEach(track => track.stop());
          return;
        }
        const audioBlob = new Blob(userAudioChunks, { type: 'audio/wav' });
        await processUserQuestionAudio(audioBlob);
        setUserRecording(false);
        userStreamRef.current?.getTracks().forEach(track => track.stop());
        setHeadTurn(getHeadTurnForCamera(camera)); // KayÄ±t bitince tekrar pozisyona dÃ¶n
      };
      mediaRecorder.start();
    } catch (error) {
      setUserRecording(false);
      setUserRecordingCancelled(false);
      userStreamRef.current?.getTracks().forEach(track => track.stop());
      console.error('Mikrofon eriÅŸimi hatasÄ±:', error);
    }
  };

  // Mikrofonu manuel bitir
  const stopUserRecording = () => {
    if (userMediaRecorderRef.current && userMediaRecorderRef.current.state === 'recording') {
      userMediaRecorderRef.current.stop();
    }
  };

  // KayÄ±t iptal
  const cancelUserRecording = () => {
    setUserRecordingCancelled(true);
    if (userMediaRecorderRef.current && userMediaRecorderRef.current.state === 'recording') {
      userMediaRecorderRef.current.stop();
    }
    setUserRecording(false);
    setShowUserResponse(false);
    setHeadTurn(getHeadTurnForCamera(camera)); // Ä°ptal edilirse tekrar pozisyona dÃ¶n
  };

  // KullanÄ±cÄ± sorusu iÃ§in Ã¶zel prompt ile AI'ya istek at
  const processUserQuestionAudio = async (audioBlob: Blob) => {
    setIsProcessingResponse(true);
    setUserAnswerMode(true); // KullanÄ±cÄ±ya Ã¶zel cevap bekleniyor
    setHeadTurn(0); // Cevap gelirken kullanÄ±cÄ±ya dÃ¶n
    try {
      const arrayBuffer = await audioBlob.arrayBuffer();
      const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
      const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
      if (!apiKey) {
        console.error("Gemini API anahtarÄ± bulunamadÄ±!");
        setIsProcessingResponse(false);
        return;
      }
      // Ã–nce sesi metne Ã§evir
      const transcriptionBody = JSON.stringify({
        contents: [
          { role: "user", parts: [
            { text: "Bu ses kaydÄ±nÄ± TÃ¼rkÃ§e metne Ã§evir. Sadece metni dÃ¶ndÃ¼r, baÅŸka hiÃ§bir ÅŸey ekleme." },
            { inline_data: { mime_type: "audio/wav", data: base64Audio } }
          ]}
        ]
      });
      const transcriptionResponse = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: transcriptionBody
      });
      const transcriptionData = await transcriptionResponse.json();
      const userText = transcriptionData?.candidates?.[0]?.content?.parts?.[0]?.text || "Ses anlaÅŸÄ±lamadÄ±";
      setUserResponseText(userText);
      setShowUserResponse(true);
      // KULLANICI_SORUSU promptu ile AI'ya gÃ¶nder
      const userPrompt = `KULLANICI_SORUSU: KullanÄ±cÄ±dan gelen sesli soru: "${userText}". LÃ¼tfen bu soruya uygun ÅŸekilde, kÄ±sa ve net bir yanÄ±t ver.`;
      const conversationBody = JSON.stringify({
        contents: [
          { role: "user", parts: [ { text: userPrompt } ] }
        ]
      });
      const conversationResponse = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: conversationBody
      });
      const conversationData = await conversationResponse.json();
      const result = conversationData?.candidates?.[0]?.content?.parts?.[0]?.text || "YanÄ±t alÄ±namadÄ±.";
      setBuddyResponse({
        delay_seconds: 0,
        target_question_number: "kullanici_sorusu",
        ai_question: result
      });
      setShowBuddyQuestion(true);
      setIsProcessingResponse(false);
    } catch (err) {
      setIsProcessingResponse(false);
      setShowBuddyQuestion(false);
      setUserAnswerMode(false);
      console.error("KullanÄ±cÄ± sorusu iÅŸlenirken hata:", err);
    }
  };

  // Buddy cevabÄ± gÃ¶sterildikten sonra userAnswerMode'u sÄ±fÄ±rla
  React.useEffect(() => {
    if (showBuddyQuestion && !isProcessingResponse && userAnswerMode) {
      setHeadTurn(0); // Cevap gÃ¶sterilirken kullanÄ±cÄ±ya dÃ¶n
      // 2 saniye sonra tekrar normal moda dÃ¶n
      const t = setTimeout(() => setUserAnswerMode(false), 2000);
      return () => clearTimeout(t);
    }
  }, [showBuddyQuestion, isProcessingResponse]);

  if (!sessionStarted && !showPositionSelector) {
    return <Lobby handleSessionStart={handleSessionStart} />;
  }

  // Masa pozisyon seÃ§im ekranÄ±
  if (showPositionSelector) {
    return (
      <div style={{
        minHeight: "100vh",
        minWidth: "100vw",
        background: "#171720",
        display: "flex",
        flexDirection: "column",
        alignItems: "center",
        justifyContent: "center",
        color: "#fff",
        fontFamily: "Poppins, Arial, Helvetica, sans-serif"
      }}>
        <div style={{
          background: "#23234a",
          borderRadius: 18,
          padding: "48px 40px",
          boxShadow: "0 8px 32px rgba(0,0,0,0.12)",
          display: "flex",
          flexDirection: "column",
          alignItems: "center"
        }}>
          <div style={{ marginBottom: 20, color: "#fff", fontSize: 24, fontWeight: 600 }}>
            CihazÄ±nÄ±z masada nerede bulunuyor?
          </div>
          <div
            style={{
              position: 'relative',
              width: 600,
              height: 350,
              marginBottom: 24,
              cursor: 'pointer',
              borderRadius: 18,
              overflow: 'hidden',
              boxShadow: '0 4px 24px rgba(124,58,237,0.10)',
              display: 'flex',
              alignItems: 'center',
              justifyContent: 'center'
            }}
            onMouseMove={handleMouseMove}
            onMouseLeave={handleMouseLeave}
            onClick={handleDeskClick}
          >
            <img
              src="/assets/lobby_desk.png"
              alt="Masa"
              style={{ 
                maxWidth: '140%', 
                maxHeight: '140%', 
                width: 'auto', 
                height: 'auto',
                display: 'block', 
                userSelect: 'none', 
                pointerEvents: 'none',
                objectFit: 'contain'
              }}
              draggable={false}
            />
            {/* Overlay alanlar */}
            {['left', 'center', 'right'].map((area) => (
              <div
                key={area}
                style={{
                  position: 'absolute',
                  top: 0,
                  left: area === 'left' ? 0 : area === 'center' ? '33.33%' : '66.66%',
                  width: '33.33%',
                  height: '100%',
                  background: hoveredArea === area ? 'rgba(124,58,237,0.18)' : 'transparent',
                  border: hoveredArea === area ? '2px solid #a78bfa' : 'none',
                  transition: 'background 0.2s, border 0.2s',
                  display: 'flex',
                  alignItems: 'center',
                  justifyContent: 'center',
                  pointerEvents: 'none',
                  zIndex: 2
                }}
              >
                {hoveredArea === area && (
                  <span style={{
                    background: '#7c3aed',
                    color: '#fff',
                    padding: '8px 18px',
                    borderRadius: 12,
                    fontSize: 18,
                    fontWeight: 600,
                    boxShadow: '0 2px 8px rgba(124,58,237,0.10)'
                  }}>{areaNames[area as keyof typeof areaNames]}</span>
                )}
              </div>
            ))}
          </div>
        </div>
      </div>
    );
  }

  // Ä°lk OCR sorgusu sÄ±rasÄ±nda loading ekranÄ± gÃ¶ster
  if (sessionStarted && loading) {
    return (
      <div style={{
        minHeight: "100vh",
        minWidth: "100vw",
        background: "#171720",
        display: "flex",
        flexDirection: "column",
        alignItems: "center",
        justifyContent: "center",
        color: "#fff",
        fontFamily: "Poppins, Arial, Helvetica, sans-serif",
        fontSize: 24,
        letterSpacing: 0.2,
        fontWeight: 600,
        position: "relative"
      }}>
        {/* Arkaplanda sahne yÃ¼kleniyor */}
        {sceneReady && (
          <div style={{
            position: "absolute",
            top: 0,
            left: 0,
            width: "100vw",
            height: "100vh",
            opacity: sceneOpacity,
            transition: "opacity 2s ease-in-out",
            zIndex: 1
          }}>
            <Canvas camera={{ position: camera.position, fov: 60 }}>
              <color attach="background" args={['#ffffff']} />
              <Experience headTurnY={headTurn} cameraTarget={camera.target} cameraPosition={camera.position} />
            </Canvas>
          </div>
        )}
        
        <div style={{
          background: "#23234a",
          borderRadius: 18,
          padding: "48px 40px",
          boxShadow: "0 8px 32px rgba(0,0,0,0.12)",
          display: "flex",
          flexDirection: "column",
          alignItems: "center",
          zIndex: 2,
          position: "relative"
        }}>
          <div className="lobby-avatar lobby-avatar-glow" style={{ width: 120, height: 120, marginBottom: 32 }}>
            <img src="/assets/character_smiling.png" alt="Karakter" style={{ width: "100%", height: "100%", borderRadius: "50%", objectFit: "cover", objectPosition: "center 40%" }} />
          </div>
          <div style={{ marginBottom: 18 }}>Materyalleri gÃ¶zden geÃ§iriyorum...</div>
          <div className="lobby-loading-spinner" style={{ width: 48, height: 48, border: "5px solid #7c3aed", borderTop: "5px solid #23234a", borderRadius: "50%", animation: "spin 1.1s linear infinite" }} />
        </div>
        <style>{`@keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }`}</style>
      </div>
    );
  }

  // Sahneye geÃ§iÅŸ iÃ§in sessionStarted && !loading && sceneReady kontrolÃ¼
  if (!sceneReady) {
    return null;
  }

  return (
    <>
      {showBuddyQuestion && buddyResponse && (
        <div style={{
          position: "absolute", top: 0, left: 0, width: "100vw", zIndex: 1000, display: "flex", justifyContent: "center", marginTop: 32
        }}>
          <div style={{
            background: "#23234a",
            color: "#fff",
            borderRadius: 16,
            padding: "18px 32px",
            fontSize: 20,
            fontWeight: 600,
            boxShadow: "0 4px 24px rgba(124,58,237,0.10)",
            maxWidth: 600
          }}>
            <div style={{ marginBottom: 8, color: "#a78bfa", fontSize: 15, fontWeight: 500 }}>
              AI Buddy'nin sorusu:
            </div>
            <div>{buddyResponse.ai_question}</div>
          </div>
        </div>
      )}

      {showUserResponse && (
        <div style={{
          position: "absolute", bottom: 120, left: 0, width: "100vw", zIndex: 1000, display: "flex", justifyContent: "center"
        }}>
          <div style={{
            background: "#1e3a8a",
            color: "#fff",
            borderRadius: 16,
            padding: "18px 32px",
            fontSize: 18,
            fontWeight: 500,
            boxShadow: "0 4px 24px rgba(30,58,138,0.15)",
            maxWidth: 500
          }}>
            <div style={{ marginBottom: 8, color: "#93c5fd", fontSize: 14, fontWeight: 500 }}>
              Senin yanÄ±tÄ±n:
            </div>
            <div>{userResponseText}</div>
            {isProcessingResponse && (
              <div style={{ marginTop: 12, fontSize: 14, color: "#93c5fd" }}>
                AI Buddy dÃ¼ÅŸÃ¼nÃ¼yor...
              </div>
            )}
          </div>
        </div>
      )}

      {/* Mikrofon butonu */}
      {showBuddyQuestion && buddyResponse && !isRecording && !isProcessingResponse && (
        <button
          onClick={startRecording}
          style={{
            position: "absolute",
            bottom: 40,
            left: "50%",
            transform: "translateX(-50%)",
            zIndex: 10,
            width: 80,
            height: 80,
            borderRadius: "50%",
            border: "none",
            background: "linear-gradient(135deg, #667eea 0%, #764ba2 100%)",
            cursor: "pointer",
            boxShadow: "0 8px 32px rgba(102, 126, 234, 0.4)",
            display: "flex",
            alignItems: "center",
            justifyContent: "center",
            transition: "all 0.3s ease",
            overflow: "hidden"
          }}
          onMouseEnter={(e) => {
            e.currentTarget.style.background = "linear-gradient(135deg, #5a6fd8 0%, #6a4190 100%)";
            e.currentTarget.style.transform = "translateX(-50%) scale(1.1)";
            e.currentTarget.style.boxShadow = "0 12px 40px rgba(102, 126, 234, 0.6)";
          }}
          onMouseLeave={(e) => {
            e.currentTarget.style.background = "linear-gradient(135deg, #667eea 0%, #764ba2 100%)";
            e.currentTarget.style.transform = "translateX(-50%) scale(1)";
            e.currentTarget.style.boxShadow = "0 8px 32px rgba(102, 126, 234, 0.4)";
          }}
        >
          <img 
            src="/assets/microfon.png" 
            alt="Mikrofon" 
            style={{ 
              width: 32, 
              height: 32, 
              filter: "brightness(0) invert(1)",
              transition: "transform 0.2s ease"
            }}
            onMouseEnter={(e) => {
              e.currentTarget.style.transform = "scale(1.1)";
            }}
            onMouseLeave={(e) => {
              e.currentTarget.style.transform = "scale(1)";
            }}
          />
        </button>
      )}

      {/* KayÄ±t gÃ¶stergesi */}
      {isRecording && (
        <div style={{
          position: "absolute",
          bottom: 40,
          left: "50%",
          transform: "translateX(-50%)",
          zIndex: 10,
          background: "#dc2626",
          color: "#fff",
          borderRadius: 16,
          padding: "12px 24px",
          fontSize: 16,
          fontWeight: 600,
          boxShadow: "0 4px 20px rgba(220,38,38,0.3)",
          display: "flex",
          alignItems: "center",
          gap: 8
        }}>
          <div style={{
            width: 12,
            height: 12,
            borderRadius: "50%",
            background: "#fff",
            animation: "pulse 1s infinite"
          }} />
          KayÄ±t yapÄ±lÄ±yor...
          <style>{`@keyframes pulse { 0% { opacity: 1; } 50% { opacity: 0.5; } 100% { opacity: 1; } }`}</style>
        </div>
      )}

      {/* Ä°ÅŸleme gÃ¶stergesi */}
      {isProcessingResponse && (
        <div style={{
          position: "absolute",
          bottom: 40,
          left: "50%",
          transform: "translateX(-50%)",
          zIndex: 10,
          background: "#059669",
          color: "#fff",
          borderRadius: 16,
          padding: "12px 24px",
          fontSize: 16,
          fontWeight: 600,
          boxShadow: "0 4px 20px rgba(5,150,105,0.3)",
          display: "flex",
          alignItems: "center",
          gap: 8
        }}>
          <div style={{
            width: 16,
            height: 16,
            border: "2px solid #fff",
            borderTop: "2px solid transparent",
            borderRadius: "50%",
            animation: "spin 1s linear infinite"
          }} />
          Ses iÅŸleniyor...
          <style>{`@keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }`}</style>
        </div>
      )}

      {/* Mikrofon butonunu her zaman ekranda gÃ¶ster */}
      {!isProcessingResponse && (
        <button
          onClick={userRecording ? stopUserRecording : startUserRecording}
          style={{
            position: "absolute",
            bottom: 40,
            left: "50%",
            transform: "translateX(-50%)",
            zIndex: 10,
            width: 80,
            height: 80,
            borderRadius: "50%",
            border: "none",
            background: userRecording ? "linear-gradient(135deg, #e74c3c 0%, #c0392b 100%)" : "linear-gradient(135deg, #667eea 0%, #764ba2 100%)",
            cursor: "pointer",
            boxShadow: userRecording ? "0 8px 32px rgba(231, 76, 60, 0.4)" : "0 8px 32px rgba(102, 126, 234, 0.4)",
            display: "flex",
            alignItems: "center",
            justifyContent: "center",
            transition: "all 0.3s ease",
            overflow: "hidden"
          }}
          onMouseEnter={(e) => {
            e.currentTarget.style.background = userRecording ? "linear-gradient(135deg, #c0392b 0%, #e74c3c 100%)" : "linear-gradient(135deg, #5a6fd8 0%, #6a4190 100%)";
            e.currentTarget.style.transform = "translateX(-50%) scale(1.1)";
            e.currentTarget.style.boxShadow = userRecording ? "0 12px 40px rgba(231, 76, 60, 0.6)" : "0 12px 40px rgba(102, 126, 234, 0.6)";
          }}
          onMouseLeave={(e) => {
            e.currentTarget.style.background = userRecording ? "linear-gradient(135deg, #e74c3c 0%, #c0392b 100%)" : "linear-gradient(135deg, #667eea 0%, #764ba2 100%)";
            e.currentTarget.style.transform = "translateX(-50%) scale(1)";
            e.currentTarget.style.boxShadow = userRecording ? "0 8px 32px rgba(231, 76, 60, 0.4)" : "0 8px 32px rgba(102, 126, 234, 0.4)";
          }}
        >
          <img 
            src="/assets/microfon.png" 
            alt="Mikrofon" 
            style={{ 
              width: 32, 
              height: 32, 
              filter: "brightness(0) invert(1)",
              transition: "transform 0.2s ease"
            }}
          />
        </button>
      )}
      {userRecording && !isProcessingResponse && (
        <button
          onClick={cancelUserRecording}
          style={{
            position: "absolute",
            bottom: 130,
            left: "50%",
            transform: "translateX(-50%)",
            zIndex: 11,
            padding: "12px 32px",
            borderRadius: 16,
            border: "none",
            background: "#e74c3c",
            color: "#fff",
            fontWeight: 600,
            fontSize: 18,
            boxShadow: "0 4px 20px rgba(231,76,60,0.3)",
            cursor: "pointer"
          }}
        >
          Ä°ptal Et
        </button>
      )}

      {/* Masa pozisyon seÃ§imi ekranÄ± */}
      {showPositionSelector && (
        <div style={{
          position: "absolute",
          top: 0,
          left: 0,
          width: "100vw",
          height: "100vh",
          background: "rgba(0,0,0,0.7)",
          display: "flex",
          flexDirection: "column",
          alignItems: "center",
          justifyContent: "center",
          zIndex: 1000
        }}>
          <div style={{
            background: "#23234a",
            borderRadius: 18,
            padding: "48px 40px",
            boxShadow: "0 8px 32px rgba(0,0,0,0.12)",
            display: "flex",
            flexDirection: "column",
            alignItems: "center"
          }}>
            <div style={{ marginBottom: 20, color: "#fff", fontSize: 24, fontWeight: 600 }}>
              Masa Pozisyonunu SeÃ§in
            </div>
            <button
              onClick={() => handlePositionSelected(CAMERA_PRESETS.karsisina)}
              style={{
                width: 200,
                height: 200,
                borderRadius: "50%",
                border: "none",
                background: selectedPosition === CAMERA_PRESETS.karsisina ? "#7c3aed" : "#444",
                color: "#fff",
                cursor: "pointer",
                boxShadow: "0 4px 20px rgba(124,58,237,0.3)",
                display: "flex",
                alignItems: "center",
                justifyContent: "center",
                fontSize: 24,
                transition: "all 0.2s ease"
              }}
              onMouseEnter={(e) => {
                e.currentTarget.style.background = "#6d28d9";
                e.currentTarget.style.transform = "scale(1.05)";
              }}
              onMouseLeave={(e) => {
                e.currentTarget.style.background = selectedPosition === CAMERA_PRESETS.karsisina ? "#7c3aed" : "#444";
                e.currentTarget.style.transform = "scale(1)";
              }}
            >
              KarÅŸÄ±sÄ±na Otur
            </button>
            <button
              onClick={() => handlePositionSelected(CAMERA_PRESETS.sagina)}
              style={{
                width: 200,
                height: 200,
                borderRadius: "50%",
                border: "none",
                background: selectedPosition === CAMERA_PRESETS.sagina ? "#7c3aed" : "#444",
                color: "#fff",
                cursor: "pointer",
                boxShadow: "0 4px 20px rgba(124,58,237,0.3)",
                display: "flex",
                alignItems: "center",
                justifyContent: "center",
                fontSize: 24,
                transition: "all 0.2s ease"
              }}
              onMouseEnter={(e) => {
                e.currentTarget.style.background = "#6d28d9";
                e.currentTarget.style.transform = "scale(1.05)";
              }}
              onMouseLeave={(e) => {
                e.currentTarget.style.background = selectedPosition === CAMERA_PRESETS.sagina ? "#7c3aed" : "#444";
                e.currentTarget.style.transform = "scale(1)";
              }}
            >
              SaÄŸÄ±na Otur
            </button>
            <button
              onClick={() => handlePositionSelected(CAMERA_PRESETS.soluna)}
              style={{
                width: 200,
                height: 200,
                borderRadius: "50%",
                border: "none",
                background: selectedPosition === CAMERA_PRESETS.soluna ? "#7c3aed" : "#444",
                color: "#fff",
                cursor: "pointer",
                boxShadow: "0 4px 20px rgba(124,58,237,0.3)",
                display: "flex",
                alignItems: "center",
                justifyContent: "center",
                fontSize: 24,
                transition: "all 0.2s ease"
              }}
              onMouseEnter={(e) => {
                e.currentTarget.style.background = "#6d28d9";
                e.currentTarget.style.transform = "scale(1.05)";
              }}
              onMouseLeave={(e) => {
                e.currentTarget.style.background = selectedPosition === CAMERA_PRESETS.soluna ? "#7c3aed" : "#444";
                e.currentTarget.style.transform = "scale(1)";
              }}
            >
              Soluna Otur
            </button>
          </div>
        </div>
      )}

      <Canvas camera={{ position: camera.position, fov: 60 }}>
        <color attach="background" args={['#ffffff']} />
        <Experience headTurnY={headTurn} cameraTarget={camera.target} cameraPosition={camera.position} />
      </Canvas>
    </>
  );
}

export default App; 