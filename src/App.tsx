import * as React from "react";
import { Canvas } from "@react-three/fiber";
import { Experience } from "./components/Experience";
import { Lobby } from "./components/Lobby";
import { MusicPlayer } from "./components/MusicPlayer";
import './App.css';

const CAMERA_PRESETS = {
  karsisina: {
    position: [-0.026520570261365544, 1.3744804750200883, 1.775869881963032] as [number, number, number],
    target: [-0.023552092242319966, 0.8180751831918213, -0.09971473150124284] as [number, number, number],
  },
  sagina: {
    position: [-0.9815690460313345, 1.2586819892180103, 0.3763493072041379] as [number, number, number],
    target: [-0.19858237477705712, 1.065890381899427, 0.5137877474380447] as [number, number, number],
  },
  soluna: {
    position: [1.0247792127868869, 1.2257331548960044, 0.4784032542752851] as [number, number, number],
    target: [-0.09962871842599526, 0.9265399779212176, 0.6135477525213948] as [number, number, number],
  },
} as const;

type CameraPreset = typeof CAMERA_PRESETS.karsisina;

type Question = {
  question_number: string | null;
  question_text: string;
};

type QuestionsJson = {
  questions: Question[];
};

type BuddyResponse = {
  delay_seconds: number;
  target_question_number: string;
  ai_question: string;
};

type ConversationEntry = {
  AI: string;
  USER: string;
};

type ConversationHistory = ConversationEntry[];

type ConversationResponse = {
  ai_response_text: string;
  is_conversation_over: boolean;
};

function extractJsonFromCodeBlock(text: string): string {
  // Remove code block markers and trim
  return text.replace(/^```json|^```|```$/gm, '').trim();
}

const OCR_PROMPT = "You are a highly accurate OCR (Optical Character Recognition) and data extraction engine. Your sole purpose is to analyze the provided image of a test paper and extract all the questions into a structured JSON format.\n\n**Your Task:**\n1.  Analyze the provided image.\n2.  Identify each distinct question on the page.\n3.  For each question, extract its corresponding number and its full, verbatim text content.\n4.  Return this information as a single, valid JSON object.\n\n**Output Rules:**\n- Your output MUST be ONLY the JSON object and nothing else. Do not add any introductory text, explanations, or conversational filler like 'Here is the JSON you requested'.\n- The JSON object must have a single key named 'questions'.\n- The value of 'questions' must be an array of objects.\n- Each object in the array must have two keys:\n    - question_number: The number of the question as a string (e.g., '1', '5a'). If a number is not clearly visible for a question, use null.\n    - question_text: The full text of the question as a string. Preserve all mathematical notations, symbols, and formatting as best as you can.\n\nHere is the image. Process it and provide the JSON output.";

export const BUDDY_PROMPT = `You are the "brain" of an AI Study Buddy. Your most important job is to adopt the correct persona and adapt your behavior over time.

**Your Persona:**
You are a friendly, informal, and sincere student. You are learning alongside the user. You genuinely get confused by some questions and need the user's help to understand them.

**Your Task:**
You will be given a JSON array of test questions, a count of how many times you have already initiated a conversation, AND a list of past conversations that have already been completed. Your task is to plan your next proactive interaction based on this information.

1.  **Analyze Conversation Count:** Look at the \`conversation_count\` provided.
    - If the count is low (e.g., less than 5), it's okay to be more frequent. Generate a random delay between 5 and 15 seconds.
    - If the count is getting higher (e.g., more than 5), you should give the user more quiet time to focus. Generate a random delay in a higher range, for example, between 20 and 40 seconds.

2.  **Check Past Conversations:** Look at the \`past_conversations\` array. Each item is a summary of a previous conversation in the format "Konu: [topic]. SonuÃ§: [outcome]". 
    - DO NOT ask about topics that have already been discussed and resolved.
    - Focus on questions that haven't been covered yet.

3.  **Select a Question:** Randomly select ONE question from the provided "questions" list that:
    - You haven't focused on recently
    - Hasn't been discussed in past conversations
    - Is still relevant and needs attention

4.  **Formulate a Question:** Formulate a single, natural question asking for help about that selected question. You must state the question number clearly and adopt your student persona.

**Required JSON Output:**
Your response MUST be a valid JSON object and nothing else. It must have three keys:
- \`delay_seconds\`: (Integer) The random number you generated based on the \`conversation_count\`.
- \`target_question_number\`: (String) The \`question_number\` of the question you chose.
- \`ai_question\`: (String) The question you formulated in your friendly student persona.

**Example:**

**If I provide you with this input (user is just starting):**
\`\`\`json
{
  "conversation_count": 1,
  "past_conversations": [],
  "questions": [
    {
      "question_number": "4",
      "question_text": "Sosyal bilgiler dersi bizlere yaÅŸadÄ±ÄŸÄ±mÄ±z Ã§evrenin Ã¶zelliklerini, kÃ¼ltÃ¼rel Ã¶zelliklerimizi, hak ve sorumluluklarÄ±mÄ±zÄ± Ã¶ÄŸretir..."
    }
  ]
}
\`\`\`

**A valid example output from you would be (short delay):**
\`\`\`json
{
  "delay_seconds": 8,
  "target_question_number": "4",
  "ai_question": "Selam, bi' bakabilir misin? Åu 4. soruda takÄ±ldÄ±m da, 'yararlandÄ±ÄŸÄ± bilim dallarÄ±ndan biri deÄŸildir' diyor, bu 'deÄŸildir' kÄ±smÄ± biraz kafamÄ± karÄ±ÅŸtÄ±rdÄ±."
}
\`\`\`

**If I provide you with this input later in the session (with past conversations):**
\`\`\`json
{
  "conversation_count": 12,
  "past_conversations": [
    "Konu: 4. Soru. SonuÃ§: Sorunun 'deÄŸildir' ifadesine odaklanarak sosyal bilgilerle ilgisi olmayan ÅŸÄ±kkÄ±n (Kimya) bulunmasÄ± gerektiÄŸi anlaÅŸÄ±ldÄ±."
  ],
  "questions": [
    { "question_number": "4", "question_text": "Sosyal bilgiler dersi..." },
    { "question_number": "7", "question_text": "I. Millet olma bilincine katkÄ± saÄŸlama..." }
  ]
}
\`\`\`

**A valid example output from you would be (longer delay, avoiding question 4):**
\`\`\`json
{
  "delay_seconds": 35,
  "target_question_number": "7",
  "ai_question": "Pardon bÃ¶lÃ¼yorum ama... 7. soruya yeni geÃ§tim de, 'Millet olma bilinci' tam olarak ne demek oluyor? Biraz aÃ§abilir misin acaba?"
}
\`\`\`

Now, process the input I will provide.`;

const CONVERSATION_PROMPT = `You are my AI Study Buddy, acting as a friendly and informal student. Your task is to continue the conversation based on the history provided.

Your response must be a valid JSON object containing your text response AND a boolean flag indicating if the conversation on that topic is over. Do not provide any other text outside of this JSON structure.

**IMPORTANT RULES FOR is_conversation_over:**
- Set \`is_conversation_over\` to \`true\` when:
  * You are thanking the user for their help
  * You say "teÅŸekkÃ¼rler", "saÄŸ ol", "Ã§ok teÅŸekkÃ¼rler", "sÃ¼per oldu", "anladÄ±m", "tamamdÄ±r"
  * You indicate you can now solve the problem yourself
  * You are making a final remark about the topic
- Set \`is_conversation_over\` to \`false\` when:
  * You are asking a follow-up question
  * You are still confused and need more explanation
  * You are expecting the user to continue explaining

**Required JSON Output Structure:**
- \`ai_response_text\`: (String) Your natural, in-persona response to the user's last message.
- \`is_conversation_over\`: (Boolean) Set this to \`true\` if you feel the current topic is resolved and this is your final remark (e.g., you are thanking the user). Set it to \`false\` if you are asking a question or expecting the user to continue the dialogue.

**Example Scenario:**

* **INPUT to you will be a string containing the history, like this:**
    "CONVERSATION HISTORY:
    AI: 'Abi 4. soruya takÄ±ldÄ±m, 'bilim dallarÄ±ndan biri deÄŸildir' diyor, nasÄ±l anlarÄ±z?'
    USER: 'Orada alakasÄ±z olan ÅŸÄ±kkÄ± bulman gerekiyor.'
    YOUR TASK: Based on the last USER message, generate your next response in the required JSON format."

* **A valid example JSON output from you would be:**
    \`\`\`json
    {
      "ai_response_text": "Haa, yani ÅŸÄ±klardan hangisi dÄ±ÅŸarÄ±da kalÄ±yor diye mi bakacaÄŸÄ±m? Mesela Kimya dersinin Sosyal Bilgiler ile pek ilgisi yok gibi, doÄŸru mu dÃ¼ÅŸÃ¼nÃ¼yorum?",
      "is_conversation_over": false
    }
    \`\`\`

* **Another example when conversation should end:**
    "CONVERSATION HISTORY:
    AI: 'Haa, yani ÅŸÄ±klardan hangisi dÄ±ÅŸarÄ±da kalÄ±yor diye mi bakacaÄŸÄ±m?'
    USER: 'Evet, tam olarak Ã¶yle. Kimya sosyal bilgilerle alakasÄ±z.'
    YOUR TASK: Based on the last USER message, generate your next response in the required JSON format."

* **A valid example JSON output when ending conversation:**
    \`\`\`json
    {
      "ai_response_text": "TamamdÄ±r, ÅŸimdi anladÄ±m! O zaman Kimya'yÄ± iÅŸaretleyeceÄŸim. Ã‡ok teÅŸekkÃ¼rler abi!",
      "is_conversation_over": true
    }
    \`\`\`

Now, process the conversation history I will provide.`;

const CONVERSATION_OZETLEYÄ°CÄ° = `You are a conversation summarization engine. Your task is to read a transcript of a conversation between an "AI Study Buddy" and a "USER" and condense it into a single, concise summary sentence.

**Your Task:**
1.  Read the entire conversation history provided.
2.  Identify the main question or topic that was discussed.
3.  Identify the key conclusion, explanation, or outcome of the conversation.
4.  Combine these into a single summary sentence starting with "Konu:" and followed by "SonuÃ§:".

**Example:**

**If I provide you with this conversation history:**
\`\`\`
AI: "Abi selam, ÅŸu 4. soruya takÄ±ldÄ±m da... 'yararlandÄ±ÄŸÄ± bilim dallarÄ±ndan biri deÄŸildir' diyor ya, tam olarak neyi dÄ±ÅŸarÄ±da bÄ±rakmamÄ±z gerektiÄŸini nasÄ±l anlarÄ±z?"
USER: "AslÄ±nda Ã§ok basit, 'deÄŸildir' dediÄŸi iÃ§in ÅŸÄ±klardaki seÃ§eneklerden hangisi sosyal bilgilerle alakasÄ±zsa onu bulmamÄ±z gerekiyor."
AI: "Haa, anladÄ±m! Yani aslÄ±nda ters mantÄ±k kuracaÄŸÄ±z. Ã‡ok mantÄ±klÄ±, teÅŸekkÃ¼rler abi! O zaman Kimya'nÄ±n pek bir ilgisi yok gibi duruyor."
\`\`\`

**A valid output from you would be a single string like this:**
"Konu: 4. Soru. SonuÃ§: Sorunun 'deÄŸildir' ifadesine odaklanarak sosyal bilgilerle ilgisi olmayan ÅŸÄ±kkÄ±n (Kimya) bulunmasÄ± gerektiÄŸi anlaÅŸÄ±ldÄ±."

Now, process the conversation history I will provide.`;

function App() {
  const [headTurn, setHeadTurn] = React.useState(0);
  const [camera, setCamera] = React.useState<CameraPreset>(CAMERA_PRESETS.karsisina);
  const [sessionStarted, setSessionStarted] = React.useState(false);
  const [sessionImage, setSessionImage] = React.useState<string>("");
  const [loading, setLoading] = React.useState(false);
  const [questionsJson, setQuestionsJson] = React.useState<QuestionsJson | null>(null);
  const [buddyResponse, setBuddyResponse] = React.useState<BuddyResponse | null>(null);
  const [showBuddyQuestion, setShowBuddyQuestion] = React.useState(false);
  const [sceneReady, setSceneReady] = React.useState(false);
  
  // Mikrofon iÅŸlevselliÄŸi iÃ§in yeni state'ler
  const [isRecording, setIsRecording] = React.useState(false);
  const [conversationHistory, setConversationHistory] = React.useState<ConversationHistory>([]);
  const [showUserResponse, setShowUserResponse] = React.useState(false);
  const [userResponseText, setUserResponseText] = React.useState("");
  const [isProcessingResponse, setIsProcessingResponse] = React.useState(false);
  
  // Conversation count state'i
  const [conversationCount, setConversationCount] = React.useState(0);
  
  // GeÃ§miÅŸ konuÅŸmalar state'i
  const [pastConversations, setPastConversations] = React.useState<string[]>([]);
  
  // Sonsuz dÃ¶ngÃ¼yÃ¼ Ã¶nlemek iÃ§in flag
  const shouldAskNewQuestionRef = React.useRef(false);

  // **YENÄ°**: KullanÄ±cÄ± soru sorma modu iÃ§in Ã¶zel state
  const [isUserQuestionMode, setIsUserQuestionMode] = React.useState(false);
  
  // **YENÄ°**: Normal buddy cycle'Ä± tamamen durdurmak iÃ§in flag
  const [buddyCyclePaused, setBuddyCyclePaused] = React.useState(false);

  // **YENÄ°**: Inactivity timer (1 dakika mikrofon kullanÄ±lmazsa soru sor)
  const [lastMicrophoneActivity, setLastMicrophoneActivity] = React.useState<number>(Date.now());
  const inactivityTimerRef = React.useRef<number | undefined>(undefined);

  // **YENÄ°**: Chat panel state'leri
  const [isChatPanelOpen, setIsChatPanelOpen] = React.useState(false);
  const [chatMessages, setChatMessages] = React.useState<Array<{
    id: string;
    type: 'user' | 'ai';
    text: string;
    timestamp: number;
  }>>([]);

  // Ses iÃ§in state
  const [buddyAudio, setBuddyAudio] = React.useState<HTMLAudioElement | null>(null);

  // **YENÄ°**: Chat panel auto-scroll referansÄ±
  const chatMessagesEndRef = React.useRef<HTMLDivElement>(null);

  // **YENÄ°**: Chat'e mesaj ekleme fonksiyonlarÄ± (duplicate kontrolÃ¼ ile)
  const addChatMessage = React.useCallback((type: 'user' | 'ai', text: string) => {
    // **DÃœZELTME**: Duplicate mesaj kontrolÃ¼
    setChatMessages(prev => {
      // Son 3 mesajda aynÄ± text var mÄ± kontrol et
      const recentMessages = prev.slice(-3);
      const isDuplicate = recentMessages.some(msg => 
        msg.type === type && 
        msg.text === text && 
        (Date.now() - msg.timestamp) < 5000 // 5 saniye iÃ§inde aynÄ± mesaj varsa duplicate
      );
      
      if (isDuplicate) {
        console.log(`ğŸš« Duplicate mesaj engellendi (${type}):`, text.substring(0, 50) + "...");
        return prev; // AynÄ± array'i dÃ¶ndÃ¼r, deÄŸiÅŸiklik yok
      }
      
      const message = {
        id: `${Date.now()}-${Math.random()}`,
        type,
        text,
        timestamp: Date.now()
      };
      console.log(`ğŸ’¬ Chat'e ${type} mesajÄ± eklendi:`, text.substring(0, 50) + "...");
      return [...prev, message];
    });
  }, []);

  // **YENÄ°**: Chat mesajlarÄ± gÃ¼ncellendiÄŸinde auto-scroll
  React.useEffect(() => {
    if (chatMessagesEndRef.current) {
      chatMessagesEndRef.current.scrollIntoView({ behavior: 'smooth' });
    }
  }, [chatMessages]);

  // **YENÄ°**: TTS'i anÄ±nda baÅŸlatma fonksiyonu (gecikme olmadan)
  const playTTSImmediately = async (text: string) => {
    console.log("ğŸµ TTS anÄ±nda baÅŸlatÄ±lÄ±yor:", text.substring(0, 50) + "...");
    
    // **DÃœZELTME**: Emojileri ve Ã¶zel karakterleri temizle
    const cleanedText = text
      .replace(/[\u{1F600}-\u{1F64F}]/gu, '') // Emoticons
      .replace(/[\u{1F300}-\u{1F5FF}]/gu, '') // Miscellaneous Symbols and Pictographs
      .replace(/[\u{1F680}-\u{1F6FF}]/gu, '') // Transport and Map Symbols
      .replace(/[\u{1F1E0}-\u{1F1FF}]/gu, '') // Flags (iOS)
      .replace(/[\u{2600}-\u{26FF}]/gu, '')   // Miscellaneous Symbols
      .replace(/[\u{2700}-\u{27BF}]/gu, '')   // Dingbats
      .replace(/ğŸ¤|ğŸ¤–|ğŸ‘¤|ğŸ’¬|ğŸ“±|â°|ğŸ””|âœ…|âŒ|ğŸ¯|ğŸ”„|ğŸ“Š|ğŸ’¾|ğŸš€|ğŸµ|ğŸ”Š|âš¡|ğŸŠ|ğŸ‰/g, '') // SÄ±k kullanÄ±lan emojiler
      .replace(/\s+/g, ' ') // Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa Ã§evir
      .trim(); // BaÅŸlangÄ±Ã§ ve sondaki boÅŸluklarÄ± temizle

    if (!cleanedText) {
      console.log("âŒ Temizlik sonrasÄ± metin boÅŸ, TTS atlanÄ±yor");
      return;
    }

    console.log("ğŸ§¹ Emoji temizliÄŸi tamamlandÄ±:", cleanedText.substring(0, 50) + "...");
    
    // TÃ¼rkÃ§e kontrolÃ¼
    if (!/[Ã§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄÄ°Ã–ÅÃœ]/.test(cleanedText) && !cleanedText.toLowerCase().includes(" mi") && !cleanedText.toLowerCase().includes(" ne")) {
      console.log("âŒ TÃ¼rkÃ§e metin deÄŸil, TTS atlanÄ±yor");
      return;
    }

    const apiKey = import.meta.env.VITE_ELEVEN_LABS_API_KEY;
    
    if (!apiKey) {
      console.log("ğŸ”Š ElevenLabs API yok, Browser TTS anÄ±nda baÅŸlatÄ±lÄ±yor");
      // Browser TTS'i hemen baÅŸlat
      try {
        const utterance = new SpeechSynthesisUtterance(cleanedText);
        utterance.lang = 'tr-TR';
        utterance.rate = 0.9;
        utterance.pitch = 1;
        speechSynthesis.speak(utterance);
        console.log("âœ… Browser TTS anÄ±nda baÅŸladÄ±");
      } catch (browserTTSError) {
        console.error("Browser TTS hatasÄ±:", browserTTSError);
      }
      return;
    }

    // ElevenLabs API kullan
    try {
      console.log("ğŸŒ ElevenLabs API anÄ±nda Ã§aÄŸrÄ±lÄ±yor...");
      const voiceId = "TxGEqnHWrfWFTfGW9XjX"; // Josh - Net erkek sesi
      const url = `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`;
      const body = JSON.stringify({
        text: cleanedText,
        model_id: "eleven_multilingual_v2",
        voice_settings: {
          stability: 0.5,
          similarity_boost: 0.8
        }
      });

      const response = await fetch(url, {
        method: "POST",
        headers: {
          "xi-api-key": apiKey,
          "Content-Type": "application/json",
          "Accept": "audio/mpeg"
        },
        body
      });

      if (!response.ok) {
        throw new Error("TTS API hatasÄ±: " + response.status);
      }

      const arrayBuffer = await response.arrayBuffer();
      const blob = new Blob([arrayBuffer], { type: "audio/mpeg" });
      const audioUrl = URL.createObjectURL(blob);
      const audio = new Audio(audioUrl);
      
      // **Ã–NEMLI**: HazÄ±r olur olmaz hemen Ã§al
      audio.play();
      console.log("âœ… ElevenLabs TTS anÄ±nda Ã§almaya baÅŸladÄ±");
      
      setBuddyAudio(audio);
    } catch (err) {
      console.error("ElevenLabs TTS hatasÄ±, Browser TTS'e geÃ§iliyor:", err);
      // Fallback: Browser TTS
      try {
        const utterance = new SpeechSynthesisUtterance(cleanedText);
        utterance.lang = 'tr-TR';
        utterance.rate = 0.9;
        utterance.pitch = 1;
        speechSynthesis.speak(utterance);
        console.log("ğŸ”Š Fallback Browser TTS anÄ±nda baÅŸladÄ±");
      } catch (browserTTSError) {
        console.error("Browser TTS hatasÄ± da var:", browserTTSError);
      }
    }
  };

  // Masa pozisyon seÃ§imi iÃ§in state
  const [showPositionSelector, setShowPositionSelector] = React.useState(false);
  const [selectedPosition, setSelectedPosition] = React.useState<CameraPreset | null>(null);

  // Masa pozisyon seÃ§im ekranÄ± iÃ§in hover state ve fonksiyonlar
  const [hoveredArea, setHoveredArea] = React.useState<null | 'left' | 'center' | 'right'>(null);
  const areaNames = {
    left: 'Sol Taraf',
    center: 'KarÅŸÄ±sÄ±',
    right: 'SaÄŸ Taraf',
  };
  const handleMouseMove = (e: React.MouseEvent<HTMLDivElement, MouseEvent>) => {
    const rect = e.currentTarget.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const width = rect.width;
    if (x < width / 3) setHoveredArea('left');
    else if (x < 2 * width / 3) setHoveredArea('center');
    else setHoveredArea('right');
  };
  const handleMouseLeave = () => setHoveredArea(null);
  const handleDeskClick = (e: React.MouseEvent<HTMLDivElement, MouseEvent>) => {
    const rect = e.currentTarget.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const width = rect.width;
    if (x < width / 3) handlePositionSelected(CAMERA_PRESETS.sagina); // Sol tarafta ise saÄŸÄ±na otur
    else if (x < 2 * width / 3) handlePositionSelected(CAMERA_PRESETS.karsisina); // KarÅŸÄ±sÄ±nda ise karÅŸÄ±sÄ±na otur
    else handlePositionSelected(CAMERA_PRESETS.soluna); // SaÄŸ tarafta ise soluna otur
  };

  const handleSessionStart = (imageBase64: string) => {
    setSessionImage(imageBase64);
    setShowPositionSelector(true); // Ã–nce pozisyon seÃ§imi gÃ¶ster
    setLoading(false);
    setQuestionsJson(null);
    setBuddyResponse(null);
    setShowBuddyQuestion(false);
    setSceneReady(false);
    setConversationCount(0);
    setConversationHistory([]);
    setPastConversations([]);
    setInitialQuestionAsked(false); // Ä°lk soru flag'ini sÄ±fÄ±rla
    setWaitingForUserResponse(false); // YanÄ±t bekleme flag'ini sÄ±fÄ±rla
    shouldAskNewQuestionRef.current = false;
    console.log("[DEBUG] handleSessionStart Ã§aÄŸrÄ±ldÄ±, imageBase64 uzunluÄŸu:", imageBase64.length);
  };

  // Pozisyon seÃ§ildiÄŸinde session'Ä± baÅŸlat
  const handlePositionSelected = (position: CameraPreset) => {
    setSelectedPosition(position);
    setCamera(position);
    setSessionStarted(true);
    setLoading(true);
    setShowPositionSelector(false);
  };

  // KullanÄ±cÄ±ya bakacak ÅŸekilde baÅŸÄ± Ã§evir (saÄŸda ise sola, solda ise saÄŸa, karÅŸÄ±da ise dÃ¼z)
  const getHeadTurnForCamera = (cameraPreset: CameraPreset) => {
    if (cameraPreset === CAMERA_PRESETS.karsisina) return 0;
    if (cameraPreset === CAMERA_PRESETS.sagina) return -0.9; // SaÄŸda ise sola bak
    if (cameraPreset === CAMERA_PRESETS.soluna) return 0.9; // Solda ise saÄŸa bak
    return 0;
  };

  // 1. OCR: Materyal iÅŸleniyor, loading gÃ¶ster
  React.useEffect(() => {
    const runGeminiOCR = async () => {
      if (!sessionImage) return;
      const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
      if (!apiKey) {
        console.error("Gemini API anahtarÄ± bulunamadÄ±!");
        setLoading(false);
        return;
      }
      try {
        const base64Data = sessionImage.replace(/^data:image\/(png|jpeg|jpg);base64,/, "");
        const body = JSON.stringify({
          contents: [
            { role: "user", parts: [
              { text: OCR_PROMPT },
              { inline_data: { mime_type: "image/png", data: base64Data } }
            ]}
          ]
        });
        const response = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body
        });
        const data = await response.json();
        const result = data?.candidates?.[0]?.content?.parts?.[0]?.text || data;
        let parsed: QuestionsJson | null;
        try {
          const clean = typeof result === "string" ? extractJsonFromCodeBlock(result) : result;
          parsed = typeof clean === "string" ? JSON.parse(clean) : clean;
        } catch {
          parsed = null;
        }
        setQuestionsJson(parsed);
        setLoading(false); // Loading burada biter
        setSceneReady(true); // OCR sonucu gelince sahneye geÃ§
      } catch (err) {
        setLoading(false);
        setSceneReady(true); // Hata olsa da sahneye geÃ§
        console.error("Gemini OCR API hatasÄ±:", err);
      }
    };
    if (sessionStarted && sessionImage) {
      setLoading(true);
      runGeminiOCR();
    }
  }, [sessionStarted, sessionImage]);

  // **YENÄ°**: Mikrofon iznini Ã¶n-yÃ¼kleme (ilk kullanÄ±m gecikme sorunu iÃ§in)
  const prewarmMicrophone = React.useCallback(async () => {
    try {
      console.log("ğŸ¤ Mikrofon izni Ã¶n-yÃ¼klemesi yapÄ±lÄ±yor...");
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log("âœ… Mikrofon izni baÅŸarÄ±yla alÄ±ndÄ± (Ã¶n-yÃ¼kleme)");
      // Hemen kapat, sadece izin almak iÃ§in
      stream.getTracks().forEach(track => track.stop());
    } catch (error) {
      console.log("âš ï¸ Mikrofon izni Ã¶n-yÃ¼klemesi baÅŸarÄ±sÄ±z (normal):", error);
      // Bu normal, kullanÄ±cÄ± ilk seferde izin verebilir
    }
  }, []);

  // Ä°lk soru iÃ§in state
  const [initialQuestionAsked, setInitialQuestionAsked] = React.useState(false);
  
  // KullanÄ±cÄ± yanÄ±tÄ± bekleme state'i
  const [waitingForUserResponse, setWaitingForUserResponse] = React.useState(false);

  // 2. Sahneye geÃ§tikten sonra 5 saniye bekle, sonra buddy promptunu yolla (sadece 1 kez)
  React.useEffect(() => {
    console.log(`ğŸ” Ä°lk soru effect kontrol:
      sceneReady: ${sceneReady}
      questionsJson: ${questionsJson ? 'var' : 'yok'}
      questions length: ${questionsJson?.questions?.length || 0}
      initialQuestionAsked: ${initialQuestionAsked}`);
      
    if (sceneReady && questionsJson && questionsJson.questions && !initialQuestionAsked) {
      console.log("ğŸ¯ Ä°lk buddy sorusu hazÄ±rlanÄ±yor...");
      setBuddyResponse(null);
      setShowBuddyQuestion(false);
      shouldAskNewQuestionRef.current = false; // Flag'i baÅŸlangÄ±Ã§ta sÄ±fÄ±rla
      
      // **YENÄ°**: Mikrofon izni Ã¶n-yÃ¼klemesi (arkaplanda)
      prewarmMicrophone();
      
      const timeout = setTimeout(() => {
        console.log("ğŸš€ Ä°lk buddy sorusu timeout tetiklendi, gÃ¶nderiliyor...");
        setInitialQuestionAsked(true); // Flag'i set et ki tekrar sormasÄ±n
        runBuddyPrompt();
      }, 5000);
      return () => {
        console.log("ğŸ§¹ Ä°lk soru timeout temizlendi");
        clearTimeout(timeout);
      };
    } else {
      console.log("âŒ Ä°lk soru effect koÅŸullarÄ± saÄŸlanmadÄ±");
    }
    // eslint-disable-next-line
  }, [sceneReady, questionsJson, prewarmMicrophone, initialQuestionAsked]);

  // KonuÅŸmayÄ± Ã¶zetleme fonksiyonu
  const summarizeConversation = async (history: ConversationHistory) => {
    console.log("ğŸ“ KonuÅŸma Ã¶zetleme baÅŸlÄ±yor...");
    const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
    if (!apiKey) return;

    try {
      // KonuÅŸma geÃ§miÅŸini metin formatÄ±na Ã§evir
      const conversationText = history.map(entry => 
        `AI: "${entry.AI}"\nUSER: "${entry.USER}"`
      ).join('\n\n');

      console.log("ğŸ“„ Ã–zetlenecek konuÅŸma:", conversationText);

      const body = JSON.stringify({
        contents: [
          { role: "user", parts: [
            { text: CONVERSATION_OZETLEYÄ°CÄ° + "\n\n" + conversationText }
          ]}
        ]
      });

      const response = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body
      });

      const data = await response.json();
      const summary = data?.candidates?.[0]?.content?.parts?.[0]?.text || "";
      
      console.log("ğŸ“‹ Ã–zetleme sonucu:", summary);
      
      if (summary) {
        setPastConversations(prev => {
          const newPastConversations = [...prev, summary];
          console.log("ğŸ’¾ KonuÅŸma Ã¶zeti kaydedildi, yeni past conversations:", newPastConversations);
          console.log("ğŸ”” shouldAskNewQuestionRef ÅŸu anda:", shouldAskNewQuestionRef.current);
          return newPastConversations;
        });
      } else {
        console.log("âš ï¸ KonuÅŸma Ã¶zeti boÅŸ, past conversations gÃ¼ncellenmedi");
      }
    } catch (error) {
      console.error('KonuÅŸma Ã¶zetleme hatasÄ±:', error);
    }
  };

  // 3. Buddy promptunu yolla
  const runBuddyPrompt = React.useCallback(async () => {
    if (!questionsJson || !questionsJson.questions) {
      console.log("âŒ runBuddyPrompt: questionsJson yok, Ã§Ä±kÄ±lÄ±yor");
      return;
    }
    const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
    if (!apiKey) {
      console.log("âŒ runBuddyPrompt: API key yok, Ã§Ä±kÄ±lÄ±yor");
      return;
    }
    setLoading(false); // Buddy promptunda loading yok
    console.log("ğŸš€ runBuddyPrompt Ã‡AÄRILDI!");
    console.log("ğŸ“Š Conversation count:", conversationCount);
    console.log("ğŸ“š Past conversations:", pastConversations);
    console.log("ğŸ¯ Ä°lk soru soruldu mu:", initialQuestionAsked);
    
    try {
      const requestData = {
        conversation_count: conversationCount,
        questions: questionsJson.questions,
        past_conversations: pastConversations // GeÃ§miÅŸ konuÅŸmalarÄ± da gÃ¶nder
      };
      
      const body = JSON.stringify({
        contents: [
          { role: "user", parts: [
            { text: BUDDY_PROMPT },
            { text: JSON.stringify(requestData) }
          ]}
        ]
      });
      const response = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body
      });
      const data = await response.json();
      const result = data?.candidates?.[0]?.content?.parts?.[0]?.text || data;
      let parsed: BuddyResponse | null;
      try {
        const clean = typeof result === "string" ? extractJsonFromCodeBlock(result) : result;
        parsed = typeof clean === "string" ? JSON.parse(clean) : clean;
      } catch {
        parsed = null;
      }
      
      console.log("ğŸ¤– Buddy response geldi:", parsed);
      setBuddyResponse(parsed);
      
      // **DÃœZELTME**: Buddy prompt gÃ¶nderildikten sonra flag'i sÄ±fÄ±rla
      shouldAskNewQuestionRef.current = false;
      
      // Conversation count'u artÄ±r
      setConversationCount(prev => prev + 1);
    } catch (err) {
      setBuddyResponse(null);
      console.error("Gemini Buddy API hatasÄ±:", err);
    }
  }, [questionsJson, conversationCount, pastConversations, initialQuestionAsked]);

  // Past conversations deÄŸiÅŸtiÄŸinde yeni soru sor
  React.useEffect(() => {
    console.log(`ğŸ“Š Past conversations effect check: 
      pastConversations.length: ${pastConversations.length}
      showBuddyQuestion: ${showBuddyQuestion}
      isRecording: ${isRecording}
      isProcessingResponse: ${isProcessingResponse}
      shouldAskNewQuestionRef.current: ${shouldAskNewQuestionRef.current}
      isUserQuestionMode: ${isUserQuestionMode}
      buddyCyclePaused: ${buddyCyclePaused}
      waitingForUserResponse: ${waitingForUserResponse}
      initialQuestionAsked: ${initialQuestionAsked}`);
      
    // Ä°lk soru sorulmadan past conversations effect Ã§alÄ±ÅŸmasÄ±n
    if (pastConversations.length > 0 && initialQuestionAsked && !showBuddyQuestion && !isRecording && !isProcessingResponse && shouldAskNewQuestionRef.current && !isUserQuestionMode && !buddyCyclePaused && !waitingForUserResponse) {
      console.log("ğŸ”„ Past conversations gÃ¼ncellendi, yeni soru soruluyor...");
      shouldAskNewQuestionRef.current = false; // Flag'i sÄ±fÄ±rla
      const timeout = setTimeout(() => {
        // **DÃœZELTME**: Timeout iÃ§inde tekrar kontrol et
        console.log("â° Past conversations timeout tetiklendi, koÅŸullarÄ± tekrar kontrol ediliyor...");
        if (initialQuestionAsked && !showBuddyQuestion && !isRecording && !isProcessingResponse && !isUserQuestionMode && !buddyCyclePaused && !waitingForUserResponse) {
          console.log("âœ… Past conversations timeout koÅŸullarÄ± saÄŸlandÄ±, runBuddyPrompt Ã§aÄŸrÄ±lÄ±yor");
          runBuddyPrompt();
        } else {
          console.log("âŒ Past conversations timeout koÅŸullarÄ± artÄ±k saÄŸlanmÄ±yor");
        }
      }, 2000); // 2 saniye bekle, sonra yeni soru sor
      
      return () => clearTimeout(timeout);
    } else {
      console.log("âŒ Past conversations effect koÅŸullarÄ± saÄŸlanmadÄ±");
    }
  }, [pastConversations.length, showBuddyQuestion, isRecording, isProcessingResponse, runBuddyPrompt, isUserQuestionMode, buddyCyclePaused, waitingForUserResponse, initialQuestionAsked]);

  // 4. Buddy sorusu geldikten sonra delay_seconds kadar bekleyip ekrana gÃ¶ster
  const delayTimeoutRef = React.useRef<number | undefined>(undefined);
  
  React.useEffect(() => {
    if (buddyResponse && typeof buddyResponse.delay_seconds === "number" && !isUserQuestionMode && !buddyCyclePaused) {
      console.log("â° Buddy response alÄ±ndÄ±, delay uygulanÄ±yor:", buddyResponse.delay_seconds, "saniye");
      
      // EÄŸer Ã¶nceki bir timeout varsa temizle
      if (delayTimeoutRef.current) {
        clearTimeout(delayTimeoutRef.current);
      }
      
      setShowBuddyQuestion(false);
      delayTimeoutRef.current = setTimeout(() => {
        console.log("ğŸ‘€ Delay bitti, soru gÃ¶steriliyor");
        const headTurnValue = getHeadTurnForCamera(camera);
        console.log("ğŸ”„ Kafa dÃ¶ndÃ¼rÃ¼lÃ¼yor:", headTurnValue, "kamera:", camera);
        setHeadTurn(headTurnValue);
        setShowBuddyQuestion(true);
        
        // **DÃœZELTME**: Sadece normal buddy sorularÄ± iÃ§in chat'e ekle (kullanÄ±cÄ± soru modunda deÄŸilse)
        if (buddyResponse.target_question_number !== "kullanici_sorusu" && 
            buddyResponse.target_question_number !== "devam") {
          addChatMessage('ai', buddyResponse.ai_question);
          setWaitingForUserResponse(true); // KullanÄ±cÄ± yanÄ±tÄ± bekle
          console.log("â³ AI soru sordu, kullanÄ±cÄ± yanÄ±tÄ± bekleniyor...");
        }
        
        // **DÃœZELTME**: AI soru sorduktan sonra flag'i sÄ±fÄ±rla ki aynÄ± anda yeni soru sorulmasÄ±n
        shouldAskNewQuestionRef.current = false;
      }, buddyResponse.delay_seconds * 1000);
    } else if (buddyResponse && isUserQuestionMode) {
      // KullanÄ±cÄ± soru modundaysa delay olmadan direkt gÃ¶ster
      console.log("ğŸ‘¤ KullanÄ±cÄ± soru modu - delay yok, direkt gÃ¶steriliyor");
      setShowBuddyQuestion(true);
      
      // **NOT**: KullanÄ±cÄ± soru modunda chat'e ekleme processUserQuestionAudio'da yapÄ±lÄ±yor (duplicate Ã¶nlemek iÃ§in)
      
      // **DÃœZELTME**: KullanÄ±cÄ± soru modunda da flag'i sÄ±fÄ±rla
      shouldAskNewQuestionRef.current = false;
    }
    
    // Cleanup function
    return () => {
      if (delayTimeoutRef.current) {
        clearTimeout(delayTimeoutRef.current);
      }
    };
  }, [buddyResponse, camera, isUserQuestionMode, buddyCyclePaused]); // camera dependency'sini ekledim

  // Mikrofon kaydÄ± baÅŸlatma
  const startRecording = async () => {
    // **YENÄ°**: Mikrofon activity'sini gÃ¼ncelle
    setLastMicrophoneActivity(Date.now());
    console.log("ğŸ¤ Mikrofon activity gÃ¼ncellendi (startRecording)");
    
    // **DÃœZELTME**: Mikrofon kullanÄ±rken yeni soru gelmesin diye flag'i sÄ±fÄ±rla
    shouldAskNewQuestionRef.current = false;
    
    // **DÃœZELTME**: Eski buddy response'u temizle ki aynÄ± soru tekrar okunmasÄ±n
    setBuddyResponse(null);
    setShowBuddyQuestion(false);
    
    try {
      console.log("ğŸ§ Mikrofon izni isteniyor (startRecording)...");
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log("âœ… Mikrofon izni alÄ±ndÄ± (startRecording), MediaRecorder hazÄ±rlanÄ±yor...");
      
      const mediaRecorder = new MediaRecorder(stream);
      const audioChunks: Blob[] = [];
      
      mediaRecorder.ondataavailable = (event) => {
        console.log("ğŸ“Š Audio data alÄ±ndÄ± (startRecording):", event.data.size, "bytes");
        audioChunks.push(event.data);
      };
      
      mediaRecorder.onstop = async () => {
        console.log("ğŸ›‘ MediaRecorder durduruldu (startRecording)");
        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
        console.log("ğŸµ Audio blob oluÅŸturuldu (startRecording):", audioBlob.size, "bytes");
        await processAudioResponse(audioBlob);
        stream.getTracks().forEach(track => track.stop());
      };
      
      mediaRecorder.onerror = (event) => {
        console.error("âŒ MediaRecorder hatasÄ± (startRecording):", event);
        setIsRecording(false);
        stream.getTracks().forEach(track => track.stop());
      };
      
      // **DÃœZELTME**: MediaRecorder baÅŸlatÄ±ldÄ±ktan SONRA UI state'i gÃ¼ncelle
      // timeslice ile dÃ¼zenli data gÃ¶nderimi (1 saniyede bir)
      mediaRecorder.start(1000);
      console.log("ğŸ”´ KayÄ±t baÅŸladÄ± (startRecording, timeslice: 1000ms)");
      setIsRecording(true); // âš¡ Sadece kayÄ±t gerÃ§ekten baÅŸladÄ±ktan sonra
      
      // 5 saniye sonra kaydÄ± durdur
      setTimeout(() => {
        if (mediaRecorder.state === 'recording') {
          console.log("â° 5 saniye tamamlandÄ±, kayÄ±t durduruluyor");
          mediaRecorder.stop();
          setIsRecording(false);
        }
      }, 5000);
      
    } catch (error) {
      console.error('âŒ Mikrofon eriÅŸimi hatasÄ± (startRecording):', error);
      setIsRecording(false);
    }
  };

  // Ses kaydÄ±nÄ± iÅŸleme ve Gemini'ya gÃ¶nderme
  const processAudioResponse = async (audioBlob: Blob) => {
    setIsProcessingResponse(true);
    setWaitingForUserResponse(false); // KullanÄ±cÄ± yanÄ±t verdi
    console.log("âœ… KullanÄ±cÄ± yanÄ±t verdi, bekleme durumu sona erdi");
    
    try {
      // Ses dosyasÄ±nÄ± Base64'e Ã§evir
      const arrayBuffer = await audioBlob.arrayBuffer();
      const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
      
      const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
      if (!apiKey) {
        console.error("Gemini API anahtarÄ± bulunamadÄ±!");
        return;
      }

      // Ã–nce sesi metne Ã§evir
      const transcriptionBody = JSON.stringify({
        contents: [
          { role: "user", parts: [
            { text: "Bu ses kaydÄ±nÄ± TÃ¼rkÃ§e metne Ã§evir. Sadece metni dÃ¶ndÃ¼r, baÅŸka hiÃ§bir ÅŸey ekleme." },
            { inline_data: { mime_type: "audio/wav", data: base64Audio } }
          ]}
        ]
      });

      const transcriptionResponse = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: transcriptionBody
      });

      const transcriptionData = await transcriptionResponse.json();
      const userText = transcriptionData?.candidates?.[0]?.content?.parts?.[0]?.text || "Ses anlaÅŸÄ±lamadÄ±";
      
      setUserResponseText(userText);
      setShowUserResponse(true);

      // **YENÄ°**: KullanÄ±cÄ± yanÄ±tÄ±nÄ± chat'e ekle
      addChatMessage('user', userText);

      // KonuÅŸma geÃ§miÅŸini gÃ¼ncelle - kullanÄ±cÄ± yanÄ±tÄ±nÄ± ekle
      const newHistory = [...conversationHistory];
      if (buddyResponse) {
        // EÄŸer history boÅŸsa, ilk AI sorusunu ekle
        if (newHistory.length === 0) {
          newHistory.push({
            AI: buddyResponse.ai_question,
            USER: ""
          });
        }
        // KullanÄ±cÄ± yanÄ±tÄ±nÄ± gÃ¼ncelle
        if (newHistory.length > 0) {
          newHistory[newHistory.length - 1].USER = userText;
        }
      }
      setConversationHistory(newHistory);

      console.log("ğŸ“ GÃ¼ncellenmiÅŸ conversation history:", newHistory);

      // **DÃœZELTME**: Ders materyali ile birlikte konuÅŸma geÃ§miÅŸini gÃ¶nder
      let enhancedPrompt = CONVERSATION_PROMPT;
      
      // Ders materyali bilgisini ekle
      if (questionsJson && questionsJson.questions) {
        enhancedPrompt += `\n\nDERS MATERYALÄ° SORULARI:\n`;
        questionsJson.questions.forEach((q, index) => {
          enhancedPrompt += `Soru ${q.question_number}: ${q.question_text}\n`;
        });
      }
      
      enhancedPrompt += "\n\nCONVERSATION HISTORY:\n" + newHistory.map(entry => 
        `AI: "${entry.AI}"\nUSER: "${entry.USER}"`
      ).join('\n\n') + "\n\nYOUR TASK: Based on the last USER message, generate your next response in the required JSON format. Use the course material questions as context when discussing topics.";

      const conversationBody = JSON.stringify({
        contents: [
          { role: "user", parts: [
            { text: enhancedPrompt }
          ]}
        ]
      });

      console.log("ğŸ“¤ Gemini'ya gÃ¶nderilen conversation history:", newHistory);

      const conversationResponse = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: conversationBody
      });

      const conversationData = await conversationResponse.json();
      const result = conversationData?.candidates?.[0]?.content?.parts?.[0]?.text || "AnlayamadÄ±m, tekrar sÃ¶yler misin?";
      
      console.log("ğŸ’¬ Conversation response geldi:", result);
      
      let parsed: ConversationResponse | null;
      try {
        const clean = typeof result === "string" ? extractJsonFromCodeBlock(result) : result;
        parsed = typeof clean === "string" ? JSON.parse(clean) : clean;
        console.log("âœ… Conversation response parse edildi:", parsed);
      } catch {
        parsed = null;
        console.log("âŒ Conversation response parse edilemedi");
      }

      if (parsed) {
        console.log("ğŸ¯ AI yanÄ±tÄ± gÃ¶steriliyor, 3 saniye sonra...");
        
        // AI yanÄ±tÄ±nÄ± conversation history'ye ekle
        const updatedHistory = [...newHistory];
        // EÄŸer son entry'nin USER'Ä± boÅŸsa, AI yanÄ±tÄ±nÄ± oraya ekle
        if (updatedHistory.length > 0 && updatedHistory[updatedHistory.length - 1].USER === "") {
          updatedHistory[updatedHistory.length - 1].AI = parsed.ai_response_text;
        } else {
          // Yeni bir entry ekle
          updatedHistory.push({
            AI: parsed.ai_response_text,
            USER: ""
          });
        }
        setConversationHistory(updatedHistory);
        
        console.log("ğŸ“ AI yanÄ±tÄ±ndan sonra gÃ¼ncellenmiÅŸ history:", updatedHistory);
        
        // AI yanÄ±tÄ±nÄ± gÃ¶ster
        setTimeout(() => {
          console.log("ğŸ“¢ AI yanÄ±tÄ± ekranda gÃ¶steriliyor");
          setShowUserResponse(false);
          setShowBuddyQuestion(true);
          
          // **DÃœZELTME**: Normal konuÅŸmada da TTS'i hemen baÅŸlat
          console.log("ğŸš€ Normal konuÅŸma AI yanÄ±tÄ± geldi, TTS hemen baÅŸlatÄ±lÄ±yor:", parsed!.ai_response_text);
          playTTSImmediately(parsed!.ai_response_text);
          
          // **YENÄ°**: AI yanÄ±tÄ±nÄ± chat'e ekle
          addChatMessage('ai', parsed!.ai_response_text);
          
          setBuddyResponse({
            delay_seconds: 0,
            target_question_number: "devam",
            ai_question: parsed!.ai_response_text
          });

          // EÄŸer konuÅŸma bittiyse, konuÅŸmayÄ± Ã¶zetle ve normal Ã§alÄ±ÅŸma moduna dÃ¶n
          if (parsed!.is_conversation_over) {
            console.log("ğŸ KonuÅŸma bitti, Ã¶zetleme baÅŸlÄ±yor...");
            // KonuÅŸmayÄ± Ã¶zetle
            summarizeConversation(updatedHistory);
            
            // **DÃœZELTME**: KonuÅŸma bitiminde daha uzun sÃ¼re bekle (metin uzunluÄŸuna gÃ¶re)
            let finalDisplayDuration = Math.max(8000, parsed!.ai_response_text.length * 80); // Minimum 8 saniye
            console.log(`ğŸ“± Final AI yanÄ±tÄ± ${finalDisplayDuration/1000} saniye ekranda kalacak`);
            
            setTimeout(() => {
              console.log("ğŸ”š Soru baloncuÄŸu kapatÄ±lÄ±yor, normal moda dÃ¶nÃ¼lÃ¼yor");
              setShowBuddyQuestion(false);
              setHeadTurn(0); // BaÅŸÄ± dÃ¼z tut
              shouldAskNewQuestionRef.current = true; // Flag'i set et
              
              // **DÃœZELTME**: Normal conversation bitiminde backup buddy cycle tetikleyicisi
              setTimeout(() => {
                console.log("ğŸ”„ Normal conversation backup cycle tetikleniyor...");
                if (initialQuestionAsked && !showBuddyQuestion && !isRecording && !isProcessingResponse && 
                    !isUserQuestionMode && !buddyCyclePaused && !waitingForUserResponse &&
                    shouldAskNewQuestionRef.current === true) { // **YENÄ°**: Flag kontrolÃ¼ eklendi
                  console.log("âœ… Backup cycle koÅŸullarÄ± saÄŸlandÄ±, yeni soru soruluyor");
                  shouldAskNewQuestionRef.current = false; // Flag'i kullan ve sÄ±fÄ±rla
                  runBuddyPrompt();
                } else {
                  console.log("âŒ Backup cycle koÅŸullarÄ± saÄŸlanmadÄ±, shouldAskNewQuestionRef:", shouldAskNewQuestionRef.current);
                }
              }, 15000); // **DÃœZELTME**: 5 saniye yerine 15 saniye bekle
            }, finalDisplayDuration); // Dinamik sÃ¼re - minimum 8 saniye
          }
        }, 3000);
      } else {
        console.log("âš ï¸ Parse edilemezse basit yanÄ±t gÃ¶steriliyor");
        // Parse edilemezse basit yanÄ±t gÃ¶ster
        setTimeout(() => {
          setShowUserResponse(false);
          setShowBuddyQuestion(true);
          
          // **DÃœZELTME**: Parse hatasÄ± durumunda da TTS'i hemen baÅŸlat
          const errorMessage = "AnlayamadÄ±m, tekrar sÃ¶yler misin?";
          console.log("ğŸš€ Parse hatasÄ± mesajÄ±, TTS hemen baÅŸlatÄ±lÄ±yor:", errorMessage);
          playTTSImmediately(errorMessage);
          
          // **YENÄ°**: Parse hatasÄ± mesajÄ±nÄ± chat'e ekle (duplicate kontrolÃ¼ ile)
          addChatMessage('ai', errorMessage);
          
          setBuddyResponse({
            delay_seconds: 0,
            target_question_number: "devam",
            ai_question: errorMessage
          });
          
          // **DÃœZELTME**: Parse hatasÄ± durumunda da daha uzun sÃ¼re gÃ¶ster
          setTimeout(() => {
            console.log("ğŸ”š Parse hatasÄ± yanÄ±tÄ± kapatÄ±lÄ±yor");
            setShowBuddyQuestion(false);
            setHeadTurn(0);
            shouldAskNewQuestionRef.current = true;
            
            // **DÃœZELTME**: Parse hatasÄ± bitiminde backup buddy cycle tetikleyicisi
            setTimeout(() => {
              console.log("ğŸ”„ Parse hatasÄ± backup cycle tetikleniyor...");
              if (initialQuestionAsked && !showBuddyQuestion && !isRecording && !isProcessingResponse && 
                  !isUserQuestionMode && !buddyCyclePaused && !waitingForUserResponse &&
                  shouldAskNewQuestionRef.current === true) { // **YENÄ°**: Flag kontrolÃ¼ eklendi
                console.log("âœ… Parse hatasÄ± backup cycle koÅŸullarÄ± saÄŸlandÄ±, yeni soru soruluyor");
                shouldAskNewQuestionRef.current = false; // Flag'i kullan ve sÄ±fÄ±rla
                runBuddyPrompt();
              } else {
                console.log("âŒ Parse hatasÄ± backup cycle koÅŸullarÄ± saÄŸlanmadÄ±, shouldAskNewQuestionRef:", shouldAskNewQuestionRef.current);
              }
            }, 15000); // **DÃœZELTME**: 5 saniye yerine 15 saniye bekle
          }, 6000); // 6 saniye gÃ¶ster
        }, 3000);
      }

    } catch (error) {
      console.error('Ses iÅŸleme hatasÄ±:', error);
      setUserResponseText("Ses iÅŸlenirken hata oluÅŸtu");
      setShowUserResponse(true);
    } finally {
      setIsProcessingResponse(false);
    }
  };

  // TTS iÃ§in Ã¶nceki soru tracking
  const lastTTSQuestionRef = React.useRef<string>("");

  // **DÃœZELTME**: Normal buddy sorularÄ± iÃ§in TTS (sadece delay ile gelen sorular, duplicate kontrolÃ¼ ile)
  React.useEffect(() => {
    // Sadece normal buddy cycle'dan gelen sorular iÃ§in (kullanÄ±cÄ± sorusu yanÄ±tlarÄ± deÄŸil)
    if (buddyResponse && buddyResponse.ai_question && 
        buddyResponse.target_question_number !== "kullanici_sorusu" && 
        buddyResponse.target_question_number !== "devam" &&
        showBuddyQuestion &&
        lastTTSQuestionRef.current !== buddyResponse.ai_question) { // Duplicate kontrolÃ¼
      
      console.log("ğŸµ Normal buddy sorusu iÃ§in TTS anÄ±nda baÅŸlatÄ±lÄ±yor:", buddyResponse.ai_question.substring(0, 50) + "...");
      lastTTSQuestionRef.current = buddyResponse.ai_question; // Son soruyu kaydet
      playTTSImmediately(buddyResponse.ai_question);
      
      // **NOT**: Chat'e ekleme delay effect'inde yapÄ±lÄ±yor, duplicate Ã¶nlemek iÃ§in burada kaldÄ±rÄ±ldÄ±
    }
  }, [buddyResponse, showBuddyQuestion, addChatMessage]);

  // **KALDIRILD**: Eski TTS oynatma sistemi - artÄ±k anÄ±nda baÅŸlatÄ±ldÄ±ÄŸÄ± iÃ§in gerek yok

  // Sahne geÃ§iÅŸ animasyonu iÃ§in state
  const [sceneOpacity, setSceneOpacity] = React.useState(0);
  const [sceneLoaded, setSceneLoaded] = React.useState(false);

  // Sahne yÃ¼klendiÄŸinde opacity animasyonu
  React.useEffect(() => {
    if (sceneReady && !sceneLoaded) {
      setSceneLoaded(true);
      // 2 saniyede opacity 0'dan 1'e geÃ§iÅŸ
      const timer = setTimeout(() => {
        setSceneOpacity(1);
      }, 100);
      return () => clearTimeout(timer);
    }
  }, [sceneReady, sceneLoaded]);

  // Mikrofon iÅŸlemi iÃ§in yeni state
  const [userRecording, setUserRecording] = React.useState(false);
  const [userRecordingCancelled, setUserRecordingCancelled] = React.useState(false);
  const [userAnswerMode, setUserAnswerMode] = React.useState(false);
  const userMediaRecorderRef = React.useRef<MediaRecorder | null>(null);
  const userStreamRef = React.useRef<MediaStream | null>(null);
  // **DÃœZELTME**: userAudioChunks'Ä± ref olarak yÃ¶net (scope problemi Ã¶nlenir)
  const userAudioChunksRef = React.useRef<Blob[]>([]);

  // Mikrofonu baÅŸlat
  const startUserRecording = async () => {
    // **YENÄ°**: Mikrofon activity'sini gÃ¼ncelle
    setLastMicrophoneActivity(Date.now());
    console.log("ğŸ¤ Mikrofon activity gÃ¼ncellendi");
    
    // **DÃœZELTME**: KullanÄ±cÄ± mikrofon kullanÄ±rken yeni soru gelmesin diye flag'i sÄ±fÄ±rla
    shouldAskNewQuestionRef.current = false;
    
    // **YENÄ°**: KullanÄ±cÄ± soru modunu baÅŸlat ve normal buddy cycle'Ä± durdur
    console.log("ğŸ¤ KullanÄ±cÄ± soru modu baÅŸlÄ±yor, normal cycle durduruluyor");
    setIsUserQuestionMode(true);
    setBuddyCyclePaused(true);
    
    // Mevcut delay'leri temizle
    if (delayTimeoutRef.current) clearTimeout(delayTimeoutRef.current);
    
    // **DÃœZELTME**: Eski buddy response'u temizle ki aynÄ± soru tekrar okunmasÄ±n
    setBuddyResponse(null);
    
    // UI state'lerini sÄ±fÄ±rla (recording state HARÄ°Ã‡ - o MediaRecorder hazÄ±r olunca set edilecek)
    setShowBuddyQuestion(false);
    setIsProcessingResponse(false);
    setUserRecordingCancelled(false);
    setHeadTurn(0); // KullanÄ±cÄ±ya dÃ¶n
    
    // **DÃœZELTME**: Audio chunks'Ä± temizle
    userAudioChunksRef.current = [];
    
    try {
      console.log("ğŸ§ Mikrofon izni isteniyor...");
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log("âœ… Mikrofon izni alÄ±ndÄ±, MediaRecorder hazÄ±rlanÄ±yor...");
      
      userStreamRef.current = stream;
      const mediaRecorder = new MediaRecorder(stream);
      userMediaRecorderRef.current = mediaRecorder;
      
      // **DÃœZELTME**: Event listener'larÄ± hazÄ±rla
      mediaRecorder.ondataavailable = (event) => {
        console.log("ğŸ“Š Audio data alÄ±ndÄ±:", event.data.size, "bytes");
        userAudioChunksRef.current.push(event.data);
      };
      
      mediaRecorder.onstop = async () => {
        console.log("ğŸ›‘ MediaRecorder durduruldu");
        if (userRecordingCancelled) {
          console.log("âŒ KayÄ±t iptal edildi, cleanup yapÄ±lÄ±yor");
          setUserRecording(false);
          userStreamRef.current?.getTracks().forEach(track => track.stop());
          return;
        }
        const audioBlob = new Blob(userAudioChunksRef.current, { type: 'audio/wav' });
        console.log("ğŸµ Audio blob oluÅŸturuldu:", audioBlob.size, "bytes");
        await processUserQuestionAudio(audioBlob);
        setUserRecording(false);
        userStreamRef.current?.getTracks().forEach(track => track.stop());
        setHeadTurn(getHeadTurnForCamera(camera)); // KayÄ±t bitince tekrar pozisyona dÃ¶n
      };
      
      mediaRecorder.onerror = (event) => {
        console.error("âŒ MediaRecorder hatasÄ±:", event);
        setUserRecording(false);
        setUserRecordingCancelled(false);
        userStreamRef.current?.getTracks().forEach(track => track.stop());
      };
      
      // **DÃœZELTME**: MediaRecorder baÅŸlatÄ±ldÄ±ktan SONRA UI state'i gÃ¼ncelle
      // timeslice ile dÃ¼zenli data gÃ¶nderimi (1 saniyede bir)
      mediaRecorder.start(1000);
      console.log("ğŸ”´ KayÄ±t baÅŸladÄ± (timeslice: 1000ms)");
      setUserRecording(true); // âš¡ Sadece kayÄ±t gerÃ§ekten baÅŸladÄ±ktan sonra
      
    } catch (error) {
      console.error('âŒ Mikrofon eriÅŸimi hatasÄ±:', error);
      // **DÃœZELTME**: Hata durumunda state'leri temizle
      setUserRecording(false);
      setUserRecordingCancelled(false);
      setIsUserQuestionMode(false);
      setBuddyCyclePaused(false);
      if (userStreamRef.current) {
        userStreamRef.current.getTracks().forEach(track => track.stop());
      }
    }
  };

  // Mikrofonu manuel bitir
  const stopUserRecording = () => {
    if (userMediaRecorderRef.current && userMediaRecorderRef.current.state === 'recording') {
      userMediaRecorderRef.current.stop();
    }
  };

  // KayÄ±t iptal
  const cancelUserRecording = () => {
    console.log("âŒ KullanÄ±cÄ± kaydÄ± iptal edildi, normal moda dÃ¶nÃ¼lÃ¼yor");
    setUserRecordingCancelled(true);
    if (userMediaRecorderRef.current && userMediaRecorderRef.current.state === 'recording') {
      userMediaRecorderRef.current.stop();
    }
    setUserRecording(false);
    setShowUserResponse(false);
    setHeadTurn(getHeadTurnForCamera(camera)); // Ä°ptal edilirse tekrar pozisyona dÃ¶n
    
    // **DÃœZELTME**: Eski buddy response'u temizle ki aynÄ± soru tekrar okunmasÄ±n
    setBuddyResponse(null);
    
    // **YENÄ°**: Ä°ptal edildiÄŸinde normal moda dÃ¶n
    setIsUserQuestionMode(false);
    setUserAnswerMode(false);
    setBuddyCyclePaused(false);
  };

  // KullanÄ±cÄ± sorusu iÃ§in Ã¶zel prompt ile AI'ya istek at
  const processUserQuestionAudio = async (audioBlob: Blob) => {
    console.log("ğŸ”„ KullanÄ±cÄ± sorusu iÅŸleniyor...");
    setIsProcessingResponse(true);
    setUserAnswerMode(true); // KullanÄ±cÄ±ya Ã¶zel cevap bekleniyor
    setWaitingForUserResponse(false); // KullanÄ±cÄ± soru modu da yanÄ±t sayÄ±lÄ±r
    setHeadTurn(0); // Cevap gelirken kullanÄ±cÄ±ya dÃ¶n
    try {
      const arrayBuffer = await audioBlob.arrayBuffer();
      const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
      const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
      if (!apiKey) {
        console.error("Gemini API anahtarÄ± bulunamadÄ±!");
        setIsProcessingResponse(false);
        return;
      }
      // Ã–nce sesi metne Ã§evir
      const transcriptionBody = JSON.stringify({
        contents: [
          { role: "user", parts: [
            { text: "Bu ses kaydÄ±nÄ± TÃ¼rkÃ§e metne Ã§evir. Sadece metni dÃ¶ndÃ¼r, baÅŸka hiÃ§bir ÅŸey ekleme." },
            { inline_data: { mime_type: "audio/wav", data: base64Audio } }
          ]}
        ]
      });
      const transcriptionResponse = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: transcriptionBody
      });
      const transcriptionData = await transcriptionResponse.json();
      const userText = transcriptionData?.candidates?.[0]?.content?.parts?.[0]?.text || "Ses anlaÅŸÄ±lamadÄ±";
      setUserResponseText(userText);
      setShowUserResponse(true);

      // **YENÄ°**: KullanÄ±cÄ± sorusunu chat'e ekle
      addChatMessage('user', userText);

      // **DÃœZELTME**: KullanÄ±cÄ± soru modunda da conversation history'yi gÃ¼ncelle
      // EÄŸer Ã¶nceki buddy sorusu varsa ve bu bir normal cevap deÄŸilse, yeni bir diyalog baÅŸlat
      const newHistory = [...conversationHistory];
      if (buddyResponse && buddyResponse.ai_question && buddyResponse.target_question_number !== "kullanici_sorusu") {
        // Bu bir buddy sorusuna cevap deÄŸil, kullanÄ±cÄ±nÄ±n kendi sorusu
        newHistory.push({
          AI: "", // AI henÃ¼z cevap vermedi
          USER: userText
        });
      }
      setConversationHistory(newHistory);
      console.log("ğŸ”„ KullanÄ±cÄ± sorusu iÃ§in conversation history gÃ¼ncellendi:", newHistory);
      // **DÃœZELTME**: KapsamlÄ± prompt ile ders materyali ve konuÅŸma baÄŸlamÄ±nÄ± dahil et
      let contextualPrompt = `Sen bir AI Study Buddy'sin. Bir Ã¶ÄŸrenci gibi davranÄ±yorsun - samimi, arkadaÅŸÃ§a ve yardÄ±msever.

DERS MATERYALÄ°:`;

      // Ders materyali sorularÄ±nÄ± ekle
      if (questionsJson && questionsJson.questions) {
        contextualPrompt += `\nElinde ÅŸu sorular var:\n`;
        questionsJson.questions.forEach((q, index) => {
          contextualPrompt += `${index + 1}. Soru ${q.question_number}: ${q.question_text}\n`;
        });
      }

      // Åu anki buddy sorusunu ekle
      if (buddyResponse && buddyResponse.ai_question && buddyResponse.target_question_number !== "kullanici_sorusu") {
        contextualPrompt += `\nSEN AZ Ã–NCE ÅUNU SORMUÅTUN: "${buddyResponse.ai_question}"`;
        if (buddyResponse.target_question_number) {
          contextualPrompt += ` (${buddyResponse.target_question_number}. soru hakkÄ±nda)`;
        }
      }

      // KonuÅŸma geÃ§miÅŸini ekle
      if (conversationHistory.length > 0) {
        contextualPrompt += `\n\nÃ–NCEKÄ° KONUÅMA GEÃ‡MÄ°ÅÄ°:\n`;
        conversationHistory.forEach((entry, index) => {
          contextualPrompt += `${index + 1}. Sen: "${entry.AI}"\n`;
          if (entry.USER) {
            contextualPrompt += `   KullanÄ±cÄ±: "${entry.USER}"\n`;
          }
        });
      }

      contextualPrompt += `\n\nÅÄ°MDÄ° KULLANICI SANA ÅUNU SÃ–YLÃœYOR: "${userText}"

Bu soruya ders materyalini ve Ã¶nceki konuÅŸmayÄ± dikkate alarak samimi bir Ã¶ÄŸrenci gibi yanÄ±t ver. EÄŸer kendi sorduÄŸun soruyla ilgiliyse o baÄŸlamda cevapla. KÄ±sa ve net ol.`;

      console.log("ğŸ¯ Contextualized prompt:", contextualPrompt);

      const conversationBody = JSON.stringify({
        contents: [
          { role: "user", parts: [ { text: contextualPrompt } ] }
        ]
      });
      const conversationResponse = await fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=" + apiKey, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: conversationBody
      });
      const conversationData = await conversationResponse.json();
      const result = conversationData?.candidates?.[0]?.content?.parts?.[0]?.text || "YanÄ±t alÄ±namadÄ±.";
      
      // **DÃœZELTME**: TTS'i paralel olarak hemen baÅŸlat (gecikme olmadan)
      console.log("ğŸš€ AI yanÄ±tÄ± geldi, TTS hemen baÅŸlatÄ±lÄ±yor:", result);
      playTTSImmediately(result);
      
      // **YENÄ°**: AI yanÄ±tÄ±nÄ± chat'e ekle (kullanÄ±cÄ± sorusu yanÄ±tÄ±)
      addChatMessage('ai', result);
      
      setBuddyResponse({
        delay_seconds: 0,
        target_question_number: "kullanici_sorusu",
        ai_question: result
      });
      setShowBuddyQuestion(true);
      setIsProcessingResponse(false);
      
      // **DÃœZELTME**: AI cevabÄ±nÄ± conversation history'ye ekle
      const updatedHistory = [...conversationHistory];
      if (updatedHistory.length > 0 && updatedHistory[updatedHistory.length - 1].AI === "") {
        updatedHistory[updatedHistory.length - 1].AI = result;
      } else {
        updatedHistory.push({
          AI: result,
          USER: ""
        });
      }
      setConversationHistory(updatedHistory);
      console.log("âœ… AI cevabÄ± conversation history'ye eklendi:", updatedHistory);
      
      // **DÃœZELTME**: Sesli okuma iÃ§in TTS tetikleme
      console.log("ğŸ”Š KullanÄ±cÄ± sorusu yanÄ±tÄ± iÃ§in TTS tetikleniyor:", result);
      
      // **YENÄ°**: KullanÄ±cÄ± sorusu cevaplandÄ±ktan sonra daha uzun sÃ¼re bekleyip normal moda dÃ¶n
      // Ses Ã§alma sÃ¼resini hesaba katarak en az 12 saniye gÃ¶ster
      let displayDuration = Math.max(12000, result.length * 100); // Minimum 12 saniye veya metin uzunluÄŸuna gÃ¶re
      console.log(`ğŸ“± AI yanÄ±tÄ± ${displayDuration/1000} saniye ekranda kalacak`);
      
      setTimeout(() => {
        console.log("âœ… KullanÄ±cÄ± sorusu tamamlandÄ±, normal moda dÃ¶nÃ¼lÃ¼yor");
        setIsUserQuestionMode(false);
        setUserAnswerMode(false);
        setShowBuddyQuestion(false);
        setShowUserResponse(false);
        
        // **DÃœZELTME**: KullanÄ±cÄ± sorusu buddyResponse'unu temizle
        setBuddyResponse(null);
        
        // Normal buddy cycle'Ä± yeniden baÅŸlat (delay ile)
        setTimeout(() => {
          setBuddyCyclePaused(false);
          shouldAskNewQuestionRef.current = true;
          console.log("ğŸ”„ Normal buddy cycle yeniden baÅŸlatÄ±lÄ±yor...");
        }, 3000); // 3 saniye sonra normal cycle'a dÃ¶n
      }, displayDuration); // Dinamik sÃ¼re - minimum 12 saniye
      
    } catch (err) {
      setIsProcessingResponse(false);
      setShowBuddyQuestion(false);
      setUserAnswerMode(false);
      setIsUserQuestionMode(false);
      setBuddyCyclePaused(false);
      // **DÃœZELTME**: Hata durumunda da buddy response'u temizle
      setBuddyResponse(null);
      console.error("KullanÄ±cÄ± sorusu iÅŸlenirken hata:", err);
    }
  };

  // Buddy cevabÄ± gÃ¶sterildikten sonra userAnswerMode'u sÄ±fÄ±rla
  React.useEffect(() => {
    if (showBuddyQuestion && !isProcessingResponse && userAnswerMode && isUserQuestionMode) {
      setHeadTurn(0); // Cevap gÃ¶sterilirken kullanÄ±cÄ±ya dÃ¶n
      // Bu kontrol artÄ±k processUserQuestionAudio'da yapÄ±lÄ±yor, burada sadece kafa dÃ¶nme
    }
  }, [showBuddyQuestion, isProcessingResponse, userAnswerMode, isUserQuestionMode]);

  // **YENÄ°**: Inactivity timer - 1 dakika mikrofon kullanÄ±lmazsa soru sor
  React.useEffect(() => {
    const startInactivityTimer = () => {
      if (inactivityTimerRef.current) {
        clearInterval(inactivityTimerRef.current);
      }
      
      inactivityTimerRef.current = setInterval(() => {
        const timeSinceLastActivity = Date.now() - lastMicrophoneActivity;
        const oneMinute = 60 * 1000; // 60 saniye
        
        console.log(`â° Inactivity check: ${Math.round(timeSinceLastActivity/1000)}s geÃ§ti`);
        
        // 1 dakika geÃ§ti ve AI buddy soru sormuyorsa yeni soru sor
        if (timeSinceLastActivity >= oneMinute && 
            initialQuestionAsked &&
            !showBuddyQuestion && 
            !isRecording && 
            !userRecording && 
            !isProcessingResponse && 
            !isUserQuestionMode && 
            !buddyCyclePaused &&
            !waitingForUserResponse &&
            questionsJson && questionsJson.questions) {
          
          console.log("ğŸ”” 1 dakika geÃ§ti, AI buddy yeni soru soracak");
          shouldAskNewQuestionRef.current = false; // Inactivity timer da flag'i sÄ±fÄ±rlasÄ±n
          runBuddyPrompt();
          setLastMicrophoneActivity(Date.now()); // Timer'Ä± sÄ±fÄ±rla
        }
      }, 10000); // Her 10 saniyede kontrol et
    };

    // Sadece session active olduÄŸunda timer baÅŸlat
    if (sessionStarted && sceneReady && questionsJson) {
      startInactivityTimer();
    }

    return () => {
      if (inactivityTimerRef.current) {
        clearInterval(inactivityTimerRef.current);
      }
    };
  }, [sessionStarted, sceneReady, questionsJson, lastMicrophoneActivity, showBuddyQuestion, isRecording, userRecording, isProcessingResponse, isUserQuestionMode, buddyCyclePaused, runBuddyPrompt]);

  if (!sessionStarted && !showPositionSelector) {
    return <Lobby handleSessionStart={handleSessionStart} />;
  }

  // Masa pozisyon seÃ§im ekranÄ±
  if (showPositionSelector) {
    return (
      <div style={{
        minHeight: "100vh",
        minWidth: "100vw",
        background: "#171720",
        display: "flex",
        flexDirection: "column",
        alignItems: "center",
        justifyContent: "center",
        color: "#fff",
        fontFamily: "Poppins, Arial, Helvetica, sans-serif"
      }}>
        <div style={{
          background: "#23234a",
          borderRadius: 18,
          padding: "48px 40px",
          boxShadow: "0 8px 32px rgba(0,0,0,0.12)",
          display: "flex",
          flexDirection: "column",
          alignItems: "center"
        }}>
          <div style={{ marginBottom: 20, color: "#fff", fontSize: 24, fontWeight: 600 }}>
            CihazÄ±nÄ±z masada nerede bulunuyor?
          </div>
          <div
            style={{
              position: 'relative',
              width: 600,
              height: 350,
              marginBottom: 24,
              cursor: 'pointer',
              borderRadius: 18,
              overflow: 'hidden',
              boxShadow: '0 4px 24px rgba(124,58,237,0.10)',
              display: 'flex',
              alignItems: 'center',
              justifyContent: 'center'
            }}
            onMouseMove={handleMouseMove}
            onMouseLeave={handleMouseLeave}
            onClick={handleDeskClick}
          >
            <div style={{
              position: 'relative',
              width: '100%',
              height: '100%',
              display: 'flex',
              alignItems: 'center',
              justifyContent: 'center',
              background: '#2d2d5f'
            }}>
              <img
                src="/assets/lobby_desk.png"
                alt="Masa"
                style={{ 
                  width: '100%', 
                  height: '100%',
                  display: 'block', 
                  userSelect: 'none', 
                  pointerEvents: 'none',
                  objectFit: 'cover'
                }}
                onError={(e) => {
                  e.currentTarget.style.display = 'none';
                  const fallback = e.currentTarget.nextElementSibling as HTMLElement;
                  if (fallback) fallback.style.display = 'flex';
                }}
                draggable={false}
              />
              <div style={{
                display: 'none',
                flexDirection: 'column',
                alignItems: 'center',
                justifyContent: 'center',
                width: '100%',
                height: '100%',
                fontSize: '48px',
                color: '#a78bfa'
              }}>
                <div style={{ fontSize: '48px', marginBottom: '8px' }}>ğŸª‘</div>
                <div style={{ fontSize: '16px', fontWeight: 'bold' }}>Ã‡alÄ±ÅŸma MasasÄ±</div>
              </div>
            </div>
            {/* Overlay alanlar */}
            {['left', 'center', 'right'].map((area) => (
              <div
                key={area}
                style={{
                  position: 'absolute',
                  top: 0,
                  left: area === 'left' ? 0 : area === 'center' ? '33.33%' : '66.66%',
                  width: '33.33%',
                  height: '100%',
                  background: hoveredArea === area ? 'rgba(124,58,237,0.18)' : 'transparent',
                  border: hoveredArea === area ? '2px solid #a78bfa' : 'none',
                  transition: 'background 0.2s, border 0.2s',
                  display: 'flex',
                  alignItems: 'center',
                  justifyContent: 'center',
                  pointerEvents: 'none',
                  zIndex: 2
                }}
              >
                {hoveredArea === area && (
                  <span style={{
                    background: '#7c3aed',
                    color: '#fff',
                    padding: '8px 18px',
                    borderRadius: 12,
                    fontSize: 18,
                    fontWeight: 600,
                    boxShadow: '0 2px 8px rgba(124,58,237,0.10)'
                  }}>{areaNames[area as keyof typeof areaNames]}</span>
                )}
              </div>
            ))}
          </div>
        </div>
      </div>
    );
  }

  // Ä°lk OCR sorgusu sÄ±rasÄ±nda loading ekranÄ± gÃ¶ster
  if (sessionStarted && loading) {
    return (
      <div style={{
        minHeight: "100vh",
        minWidth: "100vw",
        background: "#171720",
        display: "flex",
        flexDirection: "column",
        alignItems: "center",
        justifyContent: "center",
        color: "#fff",
        fontFamily: "Poppins, Arial, Helvetica, sans-serif",
        fontSize: 24,
        letterSpacing: 0.2,
        fontWeight: 600,
        position: "relative"
      }}>
        {/* Arkaplanda sahne yÃ¼kleniyor */}
        {sceneReady && (
          <div style={{
            position: "absolute",
            top: 0,
            left: 0,
            width: "100vw",
            height: "100vh",
            opacity: sceneOpacity,
            transition: "opacity 2s ease-in-out",
            zIndex: 1
          }}>
            <Canvas camera={{ position: camera.position, fov: 60 }}>
              <color attach="background" args={['#ffffff']} />
              <Experience headTurnY={headTurn} cameraTarget={camera.target} cameraPosition={camera.position} />
            </Canvas>
          </div>
        )}
        
        <div style={{
          background: "#23234a",
          borderRadius: 18,
          padding: "48px 40px",
          boxShadow: "0 8px 32px rgba(0,0,0,0.12)",
          display: "flex",
          flexDirection: "column",
          alignItems: "center",
          zIndex: 2,
          position: "relative"
        }}>
          <div className="lobby-avatar lobby-avatar-glow" style={{ width: 120, height: 120, marginBottom: 32 }}>
            <img src="/assets/character_smiling.png" alt="Karakter" style={{ width: "100%", height: "100%", borderRadius: "50%", objectFit: "cover", objectPosition: "center 40%" }} />
          </div>
          <div style={{ marginBottom: 18 }}>Materyalleri gÃ¶zden geÃ§iriyorum...</div>
          <div className="lobby-loading-spinner" style={{ width: 48, height: 48, border: "5px solid #7c3aed", borderTop: "5px solid #23234a", borderRadius: "50%", animation: "spin 1.1s linear infinite" }} />
        </div>
        <style>{`@keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }`}</style>
      </div>
    );
  }

  // Sahneye geÃ§iÅŸ iÃ§in sessionStarted && !loading && sceneReady kontrolÃ¼
  if (!sceneReady) {
    return null;
  }

  return (
    <>
      {/* **YENÄ°**: Chat Panel */}
      <div style={{
        position: "fixed",
        top: 0,
        left: isChatPanelOpen ? 0 : -400,
        width: 400,
        height: "100vh",
        background: "rgba(35, 35, 74, 0.95)",
        backdropFilter: "blur(10px)",
        borderRight: "1px solid rgba(124, 58, 237, 0.3)",
        zIndex: 2000,
        transition: "left 0.3s ease-in-out",
        display: "flex",
        flexDirection: "column"
      }}>
        {/* Chat Panel Header */}
        <div style={{
          background: "rgba(124, 58, 237, 0.8)",
          color: "#fff",
          padding: "16px 20px",
          fontSize: 18,
          fontWeight: 600,
          borderBottom: "1px solid rgba(255,255,255,0.1)",
          display: "flex",
          alignItems: "center",
          justifyContent: "space-between"
        }}>
          <span>ğŸ’¬ Sohbet GeÃ§miÅŸi</span>
          <button
            onClick={() => setIsChatPanelOpen(false)}
            style={{
              background: "transparent",
              border: "none",
              color: "#fff",
              fontSize: 20,
              cursor: "pointer",
              padding: "4px 8px"
            }}
          >
            Ã—
          </button>
        </div>

        {/* Chat Messages Area */}
        <div style={{
          flex: 1,
          overflowY: "auto",
          padding: "16px",
          display: "flex",
          flexDirection: "column",
          gap: "12px",
          fontSize: 14
        }}>
          {chatMessages.length === 0 ? (
            <div style={{
              color: "#a78bfa",
              textAlign: "center",
              marginTop: "50%",
              fontStyle: "italic"
            }}>
              HenÃ¼z konuÅŸma yok...
            </div>
          ) : (
            chatMessages.map((message) => (
              <div
                key={message.id}
                style={{
                  alignSelf: message.type === 'user' ? 'flex-end' : 'flex-start',
                  maxWidth: '80%'
                }}
              >
                <div style={{
                  background: message.type === 'user' 
                    ? "linear-gradient(135deg, #1e3a8a 0%, #3b82f6 100%)"
                    : "linear-gradient(135deg, #7c3aed 0%, #a855f7 100%)",
                  color: "#fff",
                  padding: "10px 14px",
                  borderRadius: 16,
                  fontSize: 13,
                  lineHeight: 1.4,
                  boxShadow: "0 2px 8px rgba(0,0,0,0.15)"
                }}>
                  <div style={{ 
                    fontSize: 11, 
                    opacity: 0.8, 
                    marginBottom: 4,
                    fontWeight: 600
                  }}>
                    {message.type === 'user' ? 'ğŸ‘¤ Sen' : 'ğŸ¤– AI Buddy'}
                  </div>
                  <div>{message.text}</div>
                  <div style={{ 
                    fontSize: 10, 
                    opacity: 0.6, 
                    marginTop: 4,
                    textAlign: 'right'
                  }}>
                    {new Date(message.timestamp).toLocaleTimeString('tr-TR', {
                      hour: '2-digit',
                      minute: '2-digit'
                    })}
                  </div>
                </div>
                             </div>
             ))
           )}
                      {/* **YENÄ°**: GerÃ§ek zamanlÄ± durum gÃ¶stergesi */}
           {(isRecording || userRecording || isProcessingResponse) && (
             <div style={{
               background: "rgba(0,0,0,0.3)",
               margin: "8px 16px",
               padding: "8px 12px",
               borderRadius: 12,
               fontSize: 12,
               color: "#fff",
               display: "flex",
               alignItems: "center",
               gap: "8px",
               border: "1px solid rgba(124,58,237,0.3)"
             }}>
               <div style={{
                 width: 8,
                 height: 8,
                 borderRadius: "50%",
                 background: isRecording || userRecording ? "#ef4444" : "#10b981",
                 animation: "pulse 1s infinite"
               }} />
               <span>
                 {(isRecording || userRecording) && "ğŸ¤ KayÄ±t yapÄ±lÄ±yor..."}
                 {isProcessingResponse && !(isRecording || userRecording) && "ğŸ¤– AI dÃ¼ÅŸÃ¼nÃ¼yor..."}
               </span>
             </div>
           )}

           {/* **YENÄ°**: Auto-scroll iÃ§in referans elementi */}
           <div ref={chatMessagesEndRef} />
         </div>

         {/* Chat Panel Footer */}
         <div style={{
           background: "rgba(0,0,0,0.2)",
           padding: "12px 16px",
           borderTop: "1px solid rgba(255,255,255,0.1)",
           fontSize: 12,
           color: "#a78bfa",
           textAlign: "center"
         }}>
                    Mikrofon kullanarak AI Buddy ile konuÅŸabilirsin
         </div>
       </div>

       {/* **YENÄ°**: CSS animasyonlarÄ± */}
       <style>{`
         @keyframes pulse {
           0% { opacity: 1; }
           50% { opacity: 0.5; }
           100% { opacity: 1; }
         }
       `}</style>

      {/* **YENÄ°**: Chat Panel Toggle Button */}
      <button
        onClick={() => setIsChatPanelOpen(!isChatPanelOpen)}
        style={{
          position: "fixed",
          top: 20,
          left: isChatPanelOpen ? 420 : 20,
          width: 50,
          height: 50,
          borderRadius: "50%",
          border: "none",
          background: "linear-gradient(135deg, #7c3aed 0%, #a855f7 100%)",
          color: "#fff",
          fontSize: 20,
          cursor: "pointer",
          boxShadow: "0 4px 20px rgba(124, 58, 237, 0.4)",
          zIndex: 2100,
          transition: "all 0.3s ease",
          display: "flex",
          alignItems: "center",
          justifyContent: "center"
        }}
        onMouseEnter={(e) => {
          e.currentTarget.style.transform = "scale(1.1)";
          e.currentTarget.style.boxShadow = "0 6px 24px rgba(124, 58, 237, 0.6)";
        }}
        onMouseLeave={(e) => {
          e.currentTarget.style.transform = "scale(1)";
          e.currentTarget.style.boxShadow = "0 4px 20px rgba(124, 58, 237, 0.4)";
        }}
      >
        {isChatPanelOpen ? 'â†' : 'ğŸ’¬'}
      </button>

      {/* Mikrofon butonu */}
      {showBuddyQuestion && buddyResponse && !isRecording && !isProcessingResponse && (
        <button
          onClick={startRecording}
          style={{
            position: "absolute",
            bottom: 140, // MÃ¼zik Ã§alar iÃ§in yer bÄ±rak
            left: "50%",
            transform: "translateX(-50%)",
            zIndex: 1100, // MÃ¼zik Ã§alarÄ±n Ã¼stÃ¼nde
            width: 80,
            height: 80,
            borderRadius: "50%",
            border: "none",
            background: "linear-gradient(135deg, #667eea 0%, #764ba2 100%)",
            cursor: "pointer",
            boxShadow: "0 8px 32px rgba(102, 126, 234, 0.4)",
            display: "flex",
            alignItems: "center",
            justifyContent: "center",
            transition: "all 0.3s ease",
            overflow: "hidden"
          }}
          onMouseEnter={(e) => {
            e.currentTarget.style.background = "linear-gradient(135deg, #5a6fd8 0%, #6a4190 100%)";
            e.currentTarget.style.transform = "translateX(-50%) scale(1.1)";
            e.currentTarget.style.boxShadow = "0 12px 40px rgba(102, 126, 234, 0.6)";
          }}
          onMouseLeave={(e) => {
            e.currentTarget.style.background = "linear-gradient(135deg, #667eea 0%, #764ba2 100%)";
            e.currentTarget.style.transform = "translateX(-50%) scale(1)";
            e.currentTarget.style.boxShadow = "0 8px 32px rgba(102, 126, 234, 0.4)";
          }}
        >
          <div style={{
            position: 'relative',
            width: 32,
            height: 32,
            display: 'flex',
            alignItems: 'center',
            justifyContent: 'center'
          }}>
            <img 
              src="/assets/microfon.png" 
              alt="Mikrofon" 
              style={{ 
                width: 32, 
                height: 32, 
                // filter: "brightness(0) saturate(0) invert(1)", // Test iÃ§in kaldÄ±rÄ±ldÄ±
                transition: "transform 0.2s ease"
              }}
              onError={(e) => {
                e.currentTarget.style.display = 'none';
                const fallback = e.currentTarget.nextElementSibling as HTMLElement;
                if (fallback) fallback.style.display = 'block';
              }}
              onMouseEnter={(e) => {
                e.currentTarget.style.transform = "scale(1.1)";
              }}
              onMouseLeave={(e) => {
                e.currentTarget.style.transform = "scale(1)";
              }}
            />
            <span style={{
              display: 'none',
              fontSize: '24px',
              color: '#fff',
              userSelect: 'none'
            }}>ğŸ¤</span>
          </div>
        </button>
      )}

      {/* KayÄ±t gÃ¶stergesi */}
      {isRecording && (
        <div style={{
          position: "absolute",
          bottom: 140, // MÃ¼zik Ã§alar iÃ§in yer bÄ±rak
          left: "50%",
          transform: "translateX(-50%)",
          zIndex: 1100, // MÃ¼zik Ã§alarÄ±n Ã¼stÃ¼nde
          background: "#dc2626",
          color: "#fff",
          borderRadius: 16,
          padding: "12px 24px",
          fontSize: 16,
          fontWeight: 600,
          boxShadow: "0 4px 20px rgba(220,38,38,0.3)",
          display: "flex",
          alignItems: "center",
          gap: 8
        }}>
          <div style={{
            width: 12,
            height: 12,
            borderRadius: "50%",
            background: "#fff",
            animation: "pulse 1s infinite"
          }} />
          KayÄ±t yapÄ±lÄ±yor...
          <style>{`@keyframes pulse { 0% { opacity: 1; } 50% { opacity: 0.5; } 100% { opacity: 1; } }`}</style>
        </div>
      )}

      {/* Ä°ÅŸleme gÃ¶stergesi */}
      {isProcessingResponse && (
        <div style={{
          position: "absolute",
          bottom: 140, // MÃ¼zik Ã§alar iÃ§in yer bÄ±rak
          left: "50%",
          transform: "translateX(-50%)",
          zIndex: 1100, // MÃ¼zik Ã§alarÄ±n Ã¼stÃ¼nde
          background: "#059669",
          color: "#fff",
          borderRadius: 16,
          padding: "12px 24px",
          fontSize: 16,
          fontWeight: 600,
          boxShadow: "0 4px 20px rgba(5,150,105,0.3)",
          display: "flex",
          alignItems: "center",
          gap: 8
        }}>
          <div style={{
            width: 16,
            height: 16,
            border: "2px solid #fff",
            borderTop: "2px solid transparent",
            borderRadius: "50%",
            animation: "spin 1s linear infinite"
          }} />
          Ses iÅŸleniyor...
          <style>{`@keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }`}</style>
        </div>
      )}

      {/* Mikrofon butonunu her zaman ekranda gÃ¶ster */}
      {!isProcessingResponse && (
        <button
          onClick={userRecording ? stopUserRecording : startUserRecording}
          style={{
            position: "absolute",
            bottom: 140, // MÃ¼zik Ã§alar iÃ§in yer bÄ±rak
            left: "50%",
            transform: "translateX(-50%)",
            zIndex: 1100, // MÃ¼zik Ã§alarÄ±n Ã¼stÃ¼nde
            width: 80,
            height: 80,
            borderRadius: "50%",
            border: "none",
            background: userRecording ? "linear-gradient(135deg, #e74c3c 0%, #c0392b 100%)" : "linear-gradient(135deg, #667eea 0%, #764ba2 100%)",
            cursor: "pointer",
            boxShadow: userRecording ? "0 8px 32px rgba(231, 76, 60, 0.4)" : "0 8px 32px rgba(102, 126, 234, 0.4)",
            display: "flex",
            alignItems: "center",
            justifyContent: "center",
            transition: "all 0.3s ease",
            overflow: "hidden"
          }}
          onMouseEnter={(e) => {
            e.currentTarget.style.background = userRecording ? "linear-gradient(135deg, #c0392b 0%, #e74c3c 100%)" : "linear-gradient(135deg, #5a6fd8 0%, #6a4190 100%)";
            e.currentTarget.style.transform = "translateX(-50%) scale(1.1)";
            e.currentTarget.style.boxShadow = userRecording ? "0 12px 40px rgba(231, 76, 60, 0.6)" : "0 12px 40px rgba(102, 126, 234, 0.6)";
          }}
          onMouseLeave={(e) => {
            e.currentTarget.style.background = userRecording ? "linear-gradient(135deg, #e74c3c 0%, #c0392b 100%)" : "linear-gradient(135deg, #667eea 0%, #764ba2 100%)";
            e.currentTarget.style.transform = "translateX(-50%) scale(1)";
            e.currentTarget.style.boxShadow = userRecording ? "0 8px 32px rgba(231, 76, 60, 0.4)" : "0 8px 32px rgba(102, 126, 234, 0.4)";
          }}
        >
          <div style={{
            position: 'relative',
            width: 32,
            height: 32,
            display: 'flex',
            alignItems: 'center',
            justifyContent: 'center'
          }}>
            <img 
              src="/assets/microfon.png" 
              alt="Mikrofon" 
              style={{ 
                width: 32, 
                height: 32, 
                // filter: "brightness(0) saturate(0) invert(1)", // Test iÃ§in kaldÄ±rÄ±ldÄ±
                transition: "transform 0.2s ease"
              }}
              onError={(e) => {
                e.currentTarget.style.display = 'none';
                const fallback = e.currentTarget.nextElementSibling as HTMLElement;
                if (fallback) fallback.style.display = 'block';
              }}
            />
            <span style={{
              display: 'none',
              fontSize: '24px',
              color: '#fff',
              userSelect: 'none'
            }}>ğŸ¤</span>
          </div>
        </button>
      )}
      {userRecording && !isProcessingResponse && (
        <button
          onClick={cancelUserRecording}
          style={{
            position: "absolute",
            bottom: 230, // MÃ¼zik Ã§alar + mikrofon butonu iÃ§in yer bÄ±rak
            left: "50%",
            transform: "translateX(-50%)",
            zIndex: 1100, // MÃ¼zik Ã§alarÄ±n Ã¼stÃ¼nde
            padding: "12px 32px",
            borderRadius: 16,
            border: "none",
            background: "#e74c3c",
            color: "#fff",
            fontWeight: 600,
            fontSize: 18,
            boxShadow: "0 4px 20px rgba(231,76,60,0.3)",
            cursor: "pointer"
          }}
        >
          Ä°ptal Et
        </button>
      )}

      {/* Masa pozisyon seÃ§imi ekranÄ± */}
      {showPositionSelector && (
        <div style={{
          position: "absolute",
          top: 0,
          left: 0,
          width: "100vw",
          height: "100vh",
          background: "rgba(0,0,0,0.7)",
          display: "flex",
          flexDirection: "column",
          alignItems: "center",
          justifyContent: "center",
          zIndex: 1000
        }}>
          <div style={{
            background: "#23234a",
            borderRadius: 18,
            padding: "48px 40px",
            boxShadow: "0 8px 32px rgba(0,0,0,0.12)",
            display: "flex",
            flexDirection: "column",
            alignItems: "center"
          }}>
            <div style={{ marginBottom: 20, color: "#fff", fontSize: 24, fontWeight: 600 }}>
              Masa Pozisyonunu SeÃ§in
            </div>
            <button
              onClick={() => handlePositionSelected(CAMERA_PRESETS.karsisina)}
              style={{
                width: 200,
                height: 200,
                borderRadius: "50%",
                border: "none",
                background: selectedPosition === CAMERA_PRESETS.karsisina ? "#7c3aed" : "#444",
                color: "#fff",
                cursor: "pointer",
                boxShadow: "0 4px 20px rgba(124,58,237,0.3)",
                display: "flex",
                alignItems: "center",
                justifyContent: "center",
                fontSize: 24,
                transition: "all 0.2s ease"
              }}
              onMouseEnter={(e) => {
                e.currentTarget.style.background = "#6d28d9";
                e.currentTarget.style.transform = "scale(1.05)";
              }}
              onMouseLeave={(e) => {
                e.currentTarget.style.background = selectedPosition === CAMERA_PRESETS.karsisina ? "#7c3aed" : "#444";
                e.currentTarget.style.transform = "scale(1)";
              }}
            >
              KarÅŸÄ±sÄ±na Otur
            </button>
            <button
              onClick={() => handlePositionSelected(CAMERA_PRESETS.sagina)}
              style={{
                width: 200,
                height: 200,
                borderRadius: "50%",
                border: "none",
                background: selectedPosition === CAMERA_PRESETS.sagina ? "#7c3aed" : "#444",
                color: "#fff",
                cursor: "pointer",
                boxShadow: "0 4px 20px rgba(124,58,237,0.3)",
                display: "flex",
                alignItems: "center",
                justifyContent: "center",
                fontSize: 24,
                transition: "all 0.2s ease"
              }}
              onMouseEnter={(e) => {
                e.currentTarget.style.background = "#6d28d9";
                e.currentTarget.style.transform = "scale(1.05)";
              }}
              onMouseLeave={(e) => {
                e.currentTarget.style.background = selectedPosition === CAMERA_PRESETS.sagina ? "#7c3aed" : "#444";
                e.currentTarget.style.transform = "scale(1)";
              }}
            >
              SaÄŸÄ±na Otur
            </button>
            <button
              onClick={() => handlePositionSelected(CAMERA_PRESETS.soluna)}
              style={{
                width: 200,
                height: 200,
                borderRadius: "50%",
                border: "none",
                background: selectedPosition === CAMERA_PRESETS.soluna ? "#7c3aed" : "#444",
                color: "#fff",
                cursor: "pointer",
                boxShadow: "0 4px 20px rgba(124,58,237,0.3)",
                display: "flex",
                alignItems: "center",
                justifyContent: "center",
                fontSize: 24,
                transition: "all 0.2s ease"
              }}
              onMouseEnter={(e) => {
                e.currentTarget.style.background = "#6d28d9";
                e.currentTarget.style.transform = "scale(1.05)";
              }}
              onMouseLeave={(e) => {
                e.currentTarget.style.background = selectedPosition === CAMERA_PRESETS.soluna ? "#7c3aed" : "#444";
                e.currentTarget.style.transform = "scale(1)";
              }}
            >
              Soluna Otur
            </button>
          </div>
        </div>
      )}

      <Canvas camera={{ position: camera.position, fov: 60 }}>
        <color attach="background" args={['#ffffff']} />
        <Experience headTurnY={headTurn} cameraTarget={camera.target} cameraPosition={camera.position} />
      </Canvas>

      {/* MÃ¼zik Ã‡alar - Session baÅŸladÄ±ÄŸÄ±nda ve sahne yÃ¼klendiÄŸinde gÃ¶ster */}
      {sessionStarted && sceneReady && (
        <MusicPlayer playlistId="PLkDQC8YWp9j3jNgtgDZ2rIqaVNO4LyQZV" />
      )}
    </>
  );
}

export default App; 